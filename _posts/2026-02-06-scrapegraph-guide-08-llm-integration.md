---
layout: post
title: "ScrapeGraphAI ì™„ë²½ ê°€ì´ë“œ (8) - LLM ëª¨ë¸ ì—°ë™"
date: 2026-02-06
permalink: /scrapegraph-guide-08-llm-integration/
author: ScrapeGraphAI Team
categories: [AI ë„êµ¬, ì›¹ ìŠ¤í¬ë˜í•‘]
tags: [ScrapeGraphAI, LLM, OpenAI, Anthropic, Ollama, Gemini, Groq]
original_url: "https://github.com/ScrapeGraphAI/Scrapegraph-ai"
excerpt: "ë‹¤ì–‘í•œ LLM ì œê³µìì™€ì˜ ì—°ë™ ë°©ë²•ì„ ìƒì„¸íˆ ì•Œì•„ë´…ë‹ˆë‹¤."
---

## LLM í†µí•© ê°œìš”

ScrapeGraphAIëŠ” **Langchain**ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ 20ê°œ ì´ìƒì˜ LLM ì œê³µìë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ëª¨ë¸ ì„¤ì •ë§Œ ë°”ê¾¸ë©´ ì‰½ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì§€ì› LLM ì œê³µì

| ì œê³µì | ëª¨ë¸ ì˜ˆì‹œ | ë¹„ìš© | íŠ¹ì§• |
|--------|----------|------|------|
| **OpenAI** | GPT-4o, GPT-4o-mini | ìœ ë£Œ | ë†’ì€ ì •í™•ë„, ì•ˆì •ì„± |
| **Anthropic** | Claude 3.5 Sonnet | ìœ ë£Œ | ê¸´ ì»¨í…ìŠ¤íŠ¸, ì•ˆì „ì„± |
| **Google** | Gemini Pro, Gemini Flash | ìœ ë£Œ/ë¬´ë£Œ | ë©€í‹°ëª¨ë‹¬, ë¹ ë¥¸ ì†ë„ |
| **Groq** | Llama 3, Mixtral | ë¬´ë£Œ | ì´ˆê³ ì† ì¶”ë¡  |
| **Ollama** | Llama 3.2, Mistral | ë¬´ë£Œ | ë¡œì»¬ ì‹¤í–‰, í”„ë¼ì´ë²„ì‹œ |
| **Azure OpenAI** | GPT-4, GPT-3.5 | ìœ ë£Œ | ì—”í„°í”„ë¼ì´ì¦ˆ, ì»´í”Œë¼ì´ì–¸ìŠ¤ |

## OpenAI ì—°ë™

### ê¸°ë³¸ ì„¤ì •

```python
from scrapegraphai.graphs import SmartScraperGraph

config = {
    "llm": {
        "api_key": "sk-proj-...",
        "model": "openai/gpt-4o-mini",
    }
}

scraper = SmartScraperGraph(
    prompt="Extract product information",
    source="https://example.com",
    config=config
)

result = scraper.run()
```

### í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©

```bash
export OPENAI_API_KEY="sk-proj-..."
```

```python
import os

config = {
    "llm": {
        "api_key": os.getenv("OPENAI_API_KEY"),
        "model": "openai/gpt-4o-mini",
    }
}
```

### ê³ ê¸‰ ì„¤ì •

```python
config = {
    "llm": {
        "api_key": "sk-proj-...",
        "model": "openai/gpt-4o-mini",
        "temperature": 0.0,        # ì¼ê´€ì„± (0.0 ~ 2.0)
        "max_tokens": 4096,        # ìµœëŒ€ ì¶œë ¥ í† í°
        "top_p": 1.0,              # ìƒ˜í”Œë§ í™•ë¥ 
        "frequency_penalty": 0.0,  # ë°˜ë³µ ì–µì œ
        "presence_penalty": 0.0,   # ë‹¤ì–‘ì„± ì¦ê°€
    }
}
```

### ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

```python
# ë¹ ë¥´ê³  ì €ë ´ (ì¶”ì²œ)
{"llm": {"model": "openai/gpt-4o-mini"}}  # $0.15 / 1M tokens

# ê· í˜•ì¡íŒ ì„±ëŠ¥
{"llm": {"model": "openai/gpt-4o"}}       # $2.50 / 1M tokens

# ìµœê³  ì„±ëŠ¥
{"llm": {"model": "openai/o1"}}           # $15 / 1M tokens
```

## Anthropic Claude ì—°ë™

### ê¸°ë³¸ ì„¤ì •

```python
config = {
    "llm": {
        "api_key": "sk-ant-...",
        "model": "anthropic/claude-3-5-sonnet-20241022",
    }
}
```

### Claude ëª¨ë¸ ë¹„êµ

```python
# Claude 3.5 Sonnet (ì¶”ì²œ)
{"llm": {"model": "anthropic/claude-3-5-sonnet-20241022"}}  # $3 / 1M tokens

# Claude 3 Opus (ìµœê³  ì„±ëŠ¥)
{"llm": {"model": "anthropic/claude-3-opus-20240229"}}      # $15 / 1M tokens

# Claude 3 Haiku (ë¹ ë¥´ê³  ì €ë ´)
{"llm": {"model": "anthropic/claude-3-haiku-20240307"}}     # $0.25 / 1M tokens
```

### ê¸´ ì»¨í…ìŠ¤íŠ¸ í™œìš©

```python
config = {
    "llm": {
        "api_key": "sk-ant-...",
        "model": "anthropic/claude-3-5-sonnet-20241022",
        "max_tokens": 8192,  # ClaudeëŠ” 200K í† í° ì§€ì›
    }
}

# ë§¤ìš° ê¸´ ì›¹í˜ì´ì§€ë„ ì²˜ë¦¬ ê°€ëŠ¥
scraper = SmartScraperGraph(
    prompt="Summarize this entire documentation",
    source="https://docs.example.com/full-guide",  # ê¸´ ë¬¸ì„œ
    config=config
)
```

## Google Gemini ì—°ë™

### ê¸°ë³¸ ì„¤ì •

```python
config = {
    "llm": {
        "api_key": "AIza...",
        "model": "gemini/gemini-1.5-pro",
    }
}
```

### Gemini ëª¨ë¸

```python
# Gemini 1.5 Pro (ì¶”ì²œ)
{"llm": {"model": "gemini/gemini-1.5-pro"}}    # $1.25 / 1M tokens

# Gemini 1.5 Flash (ë¹ ë¦„)
{"llm": {"model": "gemini/gemini-1.5-flash"}}  # $0.075 / 1M tokens

# Gemini 2.0 Flash (ìµœì‹ )
{"llm": {"model": "gemini/gemini-2.0-flash"}}  # ì‹¤í—˜ì 
```

### ë¬´ë£Œ í‹°ì–´

```python
# Gemini APIëŠ” ë¬´ë£Œ í‹°ì–´ ì œê³µ
config = {
    "llm": {
        "api_key": "AIza...",
        "model": "gemini/gemini-1.5-flash",  # ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥
    }
}
```

## Groq ì—°ë™ (ì´ˆê³ ì†)

GroqëŠ” **ì „ìš© LPU í•˜ë“œì›¨ì–´**ë¡œ ì´ˆê³ ì† ì¶”ë¡ ì„ ì œê³µí•©ë‹ˆë‹¤.

### ê¸°ë³¸ ì„¤ì •

```python
config = {
    "llm": {
        "api_key": "gsk_...",
        "model": "groq/llama-3.1-70b-versatile",
    }
}
```

### Groq ëª¨ë¸

```python
# Llama 3.1 70B (ì¶”ì²œ)
{"llm": {"model": "groq/llama-3.1-70b-versatile"}}

# Llama 3.1 8B (ë¹ ë¦„)
{"llm": {"model": "groq/llama-3.1-8b-instant"}}

# Mixtral 8x7B
{"llm": {"model": "groq/mixtral-8x7b-32768"}}

# Gemma 2 9B
{"llm": {"model": "groq/gemma2-9b-it"}}
```

### ì†ë„ ë¹„êµ

```python
import time

# Groq (ì´ˆê³ ì†)
start = time.time()
groq_scraper = SmartScraperGraph(
    prompt="Extract data",
    source="https://example.com",
    config={"llm": {"model": "groq/llama-3.1-8b-instant", "api_key": "gsk_..."}}
)
result = groq_scraper.run()
print(f"Groq: {time.time() - start:.2f}s")  # ~2ì´ˆ

# OpenAI (ì¼ë°˜ ì†ë„)
start = time.time()
openai_scraper = SmartScraperGraph(
    prompt="Extract data",
    source="https://example.com",
    config={"llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}}
)
result = openai_scraper.run()
print(f"OpenAI: {time.time() - start:.2f}s")  # ~5ì´ˆ
```

## Ollama ì—°ë™ (ë¡œì»¬)

### Ollama ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
# Ollama ì„¤ì¹˜
curl -fsSL https://ollama.com/install.sh | sh

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama3.2      # 3B (ê°€ë²¼ì›€)
ollama pull mistral       # 7B (ê· í˜•)
ollama pull llama3.1      # 8B (ê³ ì„±ëŠ¥)

# ì„œë²„ ì‹¤í–‰
ollama serve
```

### ê¸°ë³¸ ì„¤ì •

```python
config = {
    "llm": {
        "model": "ollama/llama3.2",
        # API í‚¤ ë¶ˆí•„ìš”
    }
}
```

### ì»¤ìŠ¤í…€ Ollama ì„œë²„

```python
config = {
    "llm": {
        "model": "ollama/llama3.2",
        "base_url": "http://localhost:11434",  # ê¸°ë³¸ê°’
    }
}

# ì›ê²© Ollama ì„œë²„
config = {
    "llm": {
        "model": "ollama/llama3.1",
        "base_url": "http://remote-server:11434",
    }
}
```

### Ollama ëª¨ë¸ ì¶”ì²œ

```python
# ë¹ ë¥¸ ìŠ¤í¬ë˜í•‘ (3B)
{"llm": {"model": "ollama/llama3.2"}}

# ê· í˜• (7B)
{"llm": {"model": "ollama/mistral"}}

# ê³ ì„±ëŠ¥ (8B)
{"llm": {"model": "ollama/llama3.1"}}

# ì½”ë“œ íŠ¹í™” (7B)
{"llm": {"model": "ollama/codellama"}}
```

## Azure OpenAI ì—°ë™

ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ëŠ” Azure OpenAI ì„œë¹„ìŠ¤:

### ê¸°ë³¸ ì„¤ì •

```python
config = {
    "llm": {
        "api_key": "YOUR_AZURE_API_KEY",
        "model": "azure/gpt-4",
        "azure_endpoint": "https://your-resource.openai.azure.com/",
        "api_version": "2024-02-15-preview",
        "azure_deployment": "gpt-4-deployment-name",
    }
}
```

### ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥

```python
config = {
    "llm": {
        "api_key": "...",
        "model": "azure/gpt-4",
        "azure_endpoint": "...",
        "azure_ad_token": "...",      # Azure AD ì¸ì¦
        "organization": "org-123",    # ì¡°ì§ ID
    }
}
```

## AWS Bedrock ì—°ë™

### ê¸°ë³¸ ì„¤ì •

```python
config = {
    "llm": {
        "model": "bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0",
        "aws_access_key_id": "AKIA...",
        "aws_secret_access_key": "...",
        "region_name": "us-east-1",
    }
}
```

## ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

### ì •í™•ë„ í…ŒìŠ¤íŠ¸

```python
models = [
    ("openai/gpt-4o-mini", "sk-..."),
    ("anthropic/claude-3-haiku", "sk-ant-..."),
    ("groq/llama-3.1-8b-instant", "gsk_..."),
    ("ollama/llama3.2", None),
]

test_url = "https://example.com/complex-page"
test_prompt = "Extract company info: name, industry, employees, revenue"

for model, api_key in models:
    config = {"llm": {"model": model}}
    if api_key:
        config["llm"]["api_key"] = api_key

    scraper = SmartScraperGraph(
        prompt=test_prompt,
        source=test_url,
        config=config
    )

    result = scraper.run()
    print(f"{model}: {result}")
```

## ë¹„ìš© ìµœì í™” ì „ëµ

### 1. ì ì ˆí•œ ëª¨ë¸ ì„ íƒ

```python
# ê°„ë‹¨í•œ ì‘ì—…: ì €ë ´í•œ ëª¨ë¸
simple_config = {"llm": {"model": "openai/gpt-4o-mini"}}  # $0.15 / 1M

# ë³µì¡í•œ ì‘ì—…: ê³ ì„±ëŠ¥ ëª¨ë¸
complex_config = {"llm": {"model": "openai/gpt-4o"}}      # $2.50 / 1M
```

### 2. ë¡œì»¬ ëª¨ë¸ í™œìš©

```python
# ë¬´ë£Œ: Ollama
free_config = {"llm": {"model": "ollama/llama3.2"}}

# ê±°ì˜ ë¬´ë£Œ: Groq (ë¬´ë£Œ í‹°ì–´)
fast_free_config = {
    "llm": {
        "model": "groq/llama-3.1-8b-instant",
        "api_key": "gsk_..."
    }
}
```

### 3. ìºì‹±

```python
config = {
    "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."},
    "cache_path": "./cache",  # HTML ìºì‹±
}
```

## ì—ëŸ¬ í•¸ë“¤ë§

### Rate Limit ì²˜ë¦¬

```python
from time import sleep

def scrape_with_retry(url, max_retries=3):
    for attempt in range(max_retries):
        try:
            scraper = SmartScraperGraph(
                prompt="Extract data",
                source=url,
                config={
                    "llm": {
                        "model": "openai/gpt-4o-mini",
                        "api_key": "sk-..."
                    }
                }
            )
            return scraper.run()
        except Exception as e:
            if "rate_limit" in str(e).lower():
                wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„
                print(f"Rate limit hit, waiting {wait_time}s...")
                sleep(wait_time)
            else:
                raise
```

### API í‚¤ ë¡œí…Œì´ì…˜

```python
api_keys = [
    "sk-proj-key1...",
    "sk-proj-key2...",
    "sk-proj-key3..."
]

current_key = 0

def get_config():
    global current_key
    config = {
        "llm": {
            "model": "openai/gpt-4o-mini",
            "api_key": api_keys[current_key]
        }
    }
    current_key = (current_key + 1) % len(api_keys)
    return config
```

## ë‹¤ìŒ ë‹¨ê³„

ë‹¤ìŒ ì±•í„°ì—ì„œëŠ” **í†µí•© ë° í™•ì¥** (API/SDK, Langchain, n8n ë“±)ì„ ë‹¤ë£¹ë‹ˆë‹¤.

---

## ì‹œë¦¬ì¦ˆ ë„¤ë¹„ê²Œì´ì…˜

- **ì´ì „**: [(7) ê³ ê¸‰ ê·¸ë˜í”„]({{ site.baseurl }}/scrapegraph-guide-07-advanced/)
- **í˜„ì¬**: (8) LLM ëª¨ë¸ ì—°ë™
- **ë‹¤ìŒ**: [(9) í†µí•© ë° í™•ì¥]({{ site.baseurl }}/scrapegraph-guide-09-integrations/)

[ğŸ“š ì „ì²´ ëª©ì°¨ë¡œ ëŒì•„ê°€ê¸°]({{ site.baseurl }}/scrapegraph-guide/)
