---
layout: post
title: "ACE-Step 1.5 ì™„ë²½ ê°€ì´ë“œ (09) - GPU ìµœì í™”"
date: 2026-02-08
permalink: /ace-step-guide-09-gpu-optimization/
author: ACE Studio & StepFun
categories: [AI ìŒì•…, ì˜¤í”ˆì†ŒìŠ¤]
tags: [ACE-Step, GPU, VRAM, Optimization, CUDA, ROCm, Intel GPU, MPS, Performance]
original_url: "https://github.com/ace-step/ACE-Step-1.5"
excerpt: "VRAMë³„ ìµœì í™” ì „ëµê³¼ GPU í˜¸í™˜ì„± ì™„ë²½ ê°€ì´ë“œ"
---

## GPU ìµœì í™” ê°œìš”

ACE-Step 1.5ëŠ” **ìë™ GPU ì ì‘ ì‹œìŠ¤í…œ**ì„ ì œê³µí•©ë‹ˆë‹¤. ì‹œì‘ ì‹œ GPUì˜ ì‚¬ìš© ê°€ëŠ¥í•œ VRAMì„ ê°ì§€í•˜ê³ , ìµœì ì˜ ì„¤ì •ì„ ìë™ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.

### ìµœì í™” ëª©í‘œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU ìë™ ê°ì§€                                             â”‚
â”‚    â†“                                                      â”‚
â”‚  VRAM ê¸°ë°˜ Tier ë¶„ë¥˜ (Tier 1~7)                           â”‚
â”‚    â†“                                                      â”‚
â”‚  ìµœì í™” ì „ëµ ì ìš©:                                          â”‚
â”‚    â€¢ LM ëª¨ë¸ ì„ íƒ (0.6B/1.7B/4B/ë¹„í™œì„±í™”)                   â”‚
â”‚    â€¢ Duration ì œí•œ (3~10ë¶„)                                â”‚
â”‚    â€¢ Batch í¬ê¸° ì¡°ì • (1~8)                                 â”‚
â”‚    â€¢ CPU Offload ìë™ í™œì„±í™”                                â”‚
â”‚    â€¢ Quantization & Compile ê¸°ë³¸ í™œì„±í™”                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## VRAMë³„ ìµœì í™” ì „ëµ

### GPU Tier êµ¬ì„±í‘œ

ACE-Step 1.5ëŠ” VRAMì— ë”°ë¼ 7ê°œì˜ Tierë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.

| VRAM | Tier | LM ëª¨ë“œ | ìµœëŒ€ Duration | ìµœëŒ€ Batch | LM ë©”ëª¨ë¦¬ í• ë‹¹ |
|------|------|---------|--------------|-----------|--------------|
| **â‰¤4GB** | Tier 1 | ì‚¬ìš© ë¶ˆê°€ | 3ë¶„ | 1 | - |
| **4-6GB** | Tier 2 | ì‚¬ìš© ë¶ˆê°€ | 6ë¶„ | 1 | - |
| **6-8GB** | Tier 3 | 0.6B (ì„ íƒ) | LM: 4ë¶„ / ì—†ìŒ: 6ë¶„ | LM: 1 / ì—†ìŒ: 2 | 3GB |
| **8-12GB** | Tier 4 | 0.6B (ì„ íƒ) | LM: 4ë¶„ / ì—†ìŒ: 6ë¶„ | LM: 2 / ì—†ìŒ: 4 | 3GB |
| **12-16GB** | Tier 5 | 0.6B / 1.7B | LM: 4ë¶„ / ì—†ìŒ: 6ë¶„ | LM: 2 / ì—†ìŒ: 4 | 0.6B: 3GB, 1.7B: 8GB |
| **16-24GB** | Tier 6 | 0.6B / 1.7B / 4B | 8ë¶„ | LM: 4 / ì—†ìŒ: 8 | 0.6B: 3GB, 1.7B: 8GB, 4B: 12GB |
| **â‰¥24GB** | Unlimited | ëª¨ë“  ëª¨ë¸ | 10ë¶„ | 8 | ì œí•œ ì—†ìŒ |

### Tierë³„ ê¶Œì¥ ì„¤ì •

#### Tier 1-2: â‰¤6GB VRAM (RTX 3060, GTX 1660 Ti)

**DiT ì „ìš© ëª¨ë“œ - LLM ë¹„í™œì„±í™”ë¡œ VRAM í™•ë³´**

```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export ACESTEP_INIT_LLM=false

# ì‹¤í–‰
uv run acestep --config_path acestep-v15-turbo
```

**íŠ¹ì§•:**
- âœ… **ë¹ ë¥¸ ìƒì„± ì†ë„** - LM ì¶”ë¡  ê³¼ì • ìƒëµ
- âœ… **ë©”ëª¨ë¦¬ ì ˆì•½** - DiTì— ì „ì²´ VRAM í• ë‹¹
- âš ï¸ **ì œí•œëœ ê¸°ëŠ¥** - CoT, Query Rewrite, Audio Understanding ë¹„í™œì„±í™”

**ê¶Œì¥ ì›Œí¬í”Œë¡œìš°:**

```python
# Simple í”„ë¡¬í”„íŠ¸ë¡œ ì§ì ‘ ìƒì„±
prompt = "upbeat electronic dance music with strong bass"
# â†’ DiTê°€ ì§ì ‘ í•´ì„í•˜ì—¬ ìƒì„± (LM ì—†ìŒ)
```

#### Tier 3-4: 6-12GB VRAM (RTX 3060 Ti, RTX 4060)

**ê²½ëŸ‰ LM ëª¨ë¸ + CPU Offload**

```bash
# ì‹¤í–‰ ì˜ˆì‹œ
uv run acestep \
  --lm_model_path acestep-5Hz-lm-0.6B \
  --offload_to_cpu true \
  --config_path acestep-v15-turbo
```

**ìµœì í™” ì„¤ì •:**

```python
# .env ì„¤ì •
ACESTEP_INIT_LLM=auto
ACESTEP_LM_MODEL_PATH=acestep-5Hz-lm-0.6B
ACESTEP_OFFLOAD_TO_CPU=true
```

**ê¶Œì¥ ì‚¬ìš© íŒ¨í„´:**
- âœ… **ì§§ì€ ìŒì•…** (1-2ë¶„) - ì•ˆì •ì  ìƒì„±
- âœ… **ë°°ì¹˜ í¬ê¸° 1-2** - ë©”ëª¨ë¦¬ ì•ˆì „
- âš ï¸ **CoT í™œìš©** - 0.6B ëª¨ë¸ì€ ì¤‘ê°„ ìˆ˜ì¤€ í’ˆì§ˆ

#### Tier 5: 12-16GB VRAM (RTX 3080, RTX 4070 Ti)

**í‘œì¤€ LM ëª¨ë¸ - ê· í˜•ì¡íŒ í’ˆì§ˆ**

```bash
# ê¶Œì¥ ì„¤ì •
uv run acestep \
  --lm_model_path acestep-5Hz-lm-1.7B \
  --config_path acestep-v15-turbo
```

**ìµœì í™” í¬ì¸íŠ¸:**

```yaml
LM Model: acestep-5Hz-lm-1.7B
Max Duration: 4ë¶„ (LM ì‚¬ìš©), 6ë¶„ (DiT only)
Batch Size: 2 (LM ì‚¬ìš©), 4 (DiT only)
Offload: Auto (í•„ìš”ì‹œ í™œì„±í™”)
Quantization: Enabled
Compile: Enabled
```

**ê¶Œì¥ ì›Œí¬í”Œë¡œìš°:**
- âœ… **í’€ì†¡ ìƒì„±** (3-4ë¶„) - ì•ˆì •ì 
- âœ… **CoT + Query Rewrite** - ì¢‹ì€ í’ˆì§ˆ
- âœ… **Cover/Repaint** - ì›í™œí•œ í¸ì§‘

#### Tier 6: 16-24GB VRAM (RTX 3090, RTX 4080)

**ëŒ€í˜• LM ëª¨ë¸ - ê³ í’ˆì§ˆ ìƒì„±**

```bash
# ê¶Œì¥ ì„¤ì •
uv run acestep \
  --lm_model_path acestep-5Hz-lm-4B \
  --config_path acestep-v15-turbo
```

**ìµœì í™” ì „ëµ:**

```python
# ë°°ì¹˜ ìƒì„± í™œìš©
settings = {
    "lm_model": "acestep-5Hz-lm-4B",
    "max_duration": 480,  # 8ë¶„
    "batch_size": 4,      # LM ì‚¬ìš© ì‹œ
    "offload_to_cpu": False,
    "quantization": True,
    "compile": True
}
```

**ê¶Œì¥ ì‚¬ìš© íŒ¨í„´:**
- âœ… **ê¸´ ê³¡ ìƒì„±** (6-8ë¶„) - ì•ˆì •ì 
- âœ… **ë°°ì¹˜ ìƒì„±** (4ê°œ ë™ì‹œ) - ë¹ ë¥¸ íƒìƒ‰
- âœ… **Audio Understanding** - ê°•ë ¥í•œ ì˜¤ë””ì˜¤ ë¶„ì„
- âœ… **ê³ í’ˆì§ˆ CoT** - 4B ëª¨ë¸ì˜ ë›°ì–´ë‚œ ë©”íƒ€ë°ì´í„° ìƒì„±

#### Tier 7: â‰¥24GB VRAM (RTX 4090, A100)

**ë¬´ì œí•œ ëª¨ë“œ - ìµœëŒ€ ì„±ëŠ¥**

```bash
# ìµœëŒ€ ì„±ëŠ¥ ì„¤ì •
uv run acestep \
  --lm_model_path acestep-5Hz-lm-4B \
  --config_path acestep-v15-turbo \
  --init_service true
```

**ìµœì í™” ì—†ì´ ìµœëŒ€ í™œìš©:**

```python
# 10ë¶„ ìŒì•… ìƒì„±
settings = {
    "duration": 600,      # 10ë¶„ (600ì´ˆ)
    "batch_size": 8,      # ìµœëŒ€ ë°°ì¹˜
    "lm_model": "4B",
    "offload": False,
    "quantization": True,
    "compile": True
}
```

**ê³ ê¸‰ ì›Œí¬í”Œë¡œìš°:**
- âœ… **ì¥í¸ ìƒì„±** (10ë¶„+) - ì™„ì „ ì§€ì›
- âœ… **ëŒ€ëŸ‰ ë°°ì¹˜** (8ê°œ ë™ì‹œ) - ë¹ ë¥¸ ë³€í˜• íƒìƒ‰
- âœ… **LoRA í›ˆë ¨** - ì—¬ìœ ë¡œìš´ VRAMìœ¼ë¡œ ë¹ ë¥¸ í›ˆë ¨
- âœ… **Multi-Track** - ë³µì¡í•œ ë‹¤ì¤‘ íŠ¸ë™ ì‘ì—…

---

## DiT ì „ìš© ëª¨ë“œ vs LLM ëª¨ë“œ

### DiT ì „ìš© ëª¨ë“œ (LLM ë¹„í™œì„±í™”)

**í™œì„±í™” ë°©ë²•:**

```bash
# ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜
export ACESTEP_INIT_LLM=false
uv run acestep

# ë°©ë²• 2: ì»¤ë§¨ë“œ ë¼ì¸
uv run acestep --init_llm false

# ë°©ë²• 3: .env íŒŒì¼
ACESTEP_INIT_LLM=false
```

**ì¥ì :**
- âš¡ **ë¹ ë¥¸ ìƒì„±** - LM ì¶”ë¡  ê³¼ì • ìƒëµ (ì•½ 30-50% ë¹ ë¦„)
- ğŸ’¾ **ë‚®ì€ VRAM** - LM ë©”ëª¨ë¦¬ ì—†ì´ DiTì— ì§‘ì¤‘
- ğŸš€ **ë†’ì€ Duration** - Tier 3ì—ì„œë„ 6ë¶„ ìƒì„± ê°€ëŠ¥

**ë‹¨ì :**
- âŒ **CoT ë¹„í™œì„±í™”** - ë©”íƒ€ë°ì´í„° ìë™ ìƒì„± ì—†ìŒ
- âŒ **Query Rewrite ì—†ìŒ** - ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ ì§ì ‘ ì‚¬ìš©
- âŒ **Audio Understanding ì—†ìŒ** - ì˜¤ë””ì˜¤ ë¶„ì„ ê¸°ëŠ¥ ë¹„í™œì„±í™”

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:**
```python
# DiT only - ì§ì ‘ì ì¸ í”„ë¡¬í”„íŠ¸
prompt = "epic orchestral soundtrack with strings and brass"
# â†’ DiTê°€ ì§ì ‘ í•´ì„, ë¹ ë¥´ê²Œ ìƒì„±

# LM ëª¨ë“œì—ì„œëŠ”:
# User Query â†’ LM (CoT) â†’ Metadata + Caption â†’ DiT
# DiT onlyì—ì„œëŠ”:
# User Query â†’ DiT (ì§ì ‘)
```

### LLM ëª¨ë“œ (Chain-of-Thought)

**í™œì„±í™” ë°©ë²•:**

```bash
# ìë™ ê°ì§€ (ê¶Œì¥)
uv run acestep  # VRAM > 6GBì´ë©´ ìë™ í™œì„±í™”

# ê°•ì œ í™œì„±í™” (ìœ„í—˜: OOM ê°€ëŠ¥)
uv run acestep --init_llm true --lm_model_path acestep-5Hz-lm-0.6B
```

**LM ëª¨ë¸ë³„ íŠ¹ì§•:**

| ëª¨ë¸ | í¬ê¸° | VRAM | CoT í’ˆì§ˆ | Audio Understanding | Query Rewrite |
|------|------|------|---------|---------------------|---------------|
| **0.6B** | ~600MB | 6-12GB | ì¤‘ê°„ | ì¤‘ê°„ | âœ… |
| **1.7B** | ~1.7GB | 12-16GB | ì¢‹ìŒ | ì¢‹ìŒ | âœ… |
| **4B** | ~4GB | 16GB+ | ë›°ì–´ë‚¨ | ê°•ë ¥í•¨ | âœ… |

**LM ëª¨ë“œ ì›Œí¬í”Œë¡œìš°:**

```python
# 1. User Query (ê°„ë‹¨í•œ ì…ë ¥)
query = "chill lofi hip hop for studying"

# 2. LM Chain-of-Thought ìƒì„±
cot_output = {
    "duration": 180,
    "bpm": 85,
    "key": "C major",
    "time_signature": "4/4",
    "caption": "Relaxing lofi hip hop beat with mellow piano, soft drums, and vinyl crackle",
    "structure": "intro, verse, chorus, verse, outro"
}

# 3. DiT ìƒì„± (LMì˜ ë¸”ë£¨í”„ë¦°íŠ¸ ê¸°ë°˜)
generated_audio = dit_generate(cot_output)
```

**ì¥ì :**
- ğŸ¯ **ì •êµí•œ ë©”íƒ€ë°ì´í„°** - ìë™ìœ¼ë¡œ BPM, Key, Structure ìƒì„±
- ğŸ¨ **ì°½ì˜ì  í™•ì¥** - ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ í’ë¶€í•œ ìº¡ì…˜ìœ¼ë¡œ í™•ì¥
- ğŸ” **Audio Understanding** - ì°¸ì¡° ì˜¤ë””ì˜¤ ë¶„ì„ (4B ëª¨ë¸ ê°•ë ¥)

---

## CPU ì˜¤í”„ë¡œë“œ (offload_to_cpu)

### CPU Offloadë€?

**VRAMì´ ë¶€ì¡±í•  ë•Œ, ì¼ë¶€ ëª¨ë¸ ë ˆì´ì–´ë¥¼ CPU RAMìœ¼ë¡œ ì´ë™í•˜ì—¬ GPU ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•©ë‹ˆë‹¤.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU VRAM (Limited)                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  â€¢ DiT Core Layers (í•„ìˆ˜)               â”‚
â”‚  â€¢ LM Active Layers (ì¶”ë¡  ì¤‘)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†• (Offload)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CPU RAM (Larger)                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  â€¢ LM Inactive Layers                   â”‚
â”‚  â€¢ DiT Non-Critical Layers              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìë™ í™œì„±í™” ì¡°ê±´

```python
# ACE-Step ë‚´ë¶€ ë¡œì§
if vram < 16_000:  # 16GB ë¯¸ë§Œ
    offload_to_cpu = True
else:
    offload_to_cpu = False
```

### ìˆ˜ë™ ì œì–´

```bash
# ê°•ì œ í™œì„±í™” (VRAM ì ˆì•½)
uv run acestep --offload_to_cpu true

# ê°•ì œ ë¹„í™œì„±í™” (ë¹ ë¥¸ ìƒì„±)
uv run acestep --offload_to_cpu false

# í™˜ê²½ë³€ìˆ˜
export ACESTEP_OFFLOAD_TO_CPU=true
```

### ì„±ëŠ¥ ë¹„êµ

| ì„¤ì • | VRAM ì‚¬ìš©ëŸ‰ | ìƒì„± ì†ë„ | ê¶Œì¥ ì‹œë‚˜ë¦¬ì˜¤ |
|------|------------|----------|--------------|
| **Offload: True** | ë‚®ìŒ (-30%) | ì¤‘ê°„ (-10~20% ëŠë¦¼) | VRAM < 16GB |
| **Offload: False** | ë†’ìŒ | ë¹ ë¦„ | VRAM â‰¥ 16GB |

**ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ (RTX 3080 12GB):**

```yaml
# Offload: True
- VRAM: 8.5GB
- ìƒì„± ì‹œê°„ (3ë¶„ ìŒì•…): 12ì´ˆ

# Offload: False
- VRAM: 11.2GB
- ìƒì„± ì‹œê°„ (3ë¶„ ìŒì•…): 10ì´ˆ
```

---

## Quantization & Compile

### Quantization (ì–‘ìí™”)

**ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì€ ì •ë°€ë„ë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ì™€ ì—°ì‚°ëŸ‰ ê°ì†Œ**

```python
# ê¸°ë³¸ í™œì„±í™” (ìë™)
quantization = True  # FP16 ë˜ëŠ” INT8

# íš¨ê³¼:
# - VRAM ì‚¬ìš©ëŸ‰: -20~30%
# - ìƒì„± ì†ë„: +10~20% ë¹ ë¦„
# - í’ˆì§ˆ ì†ì‹¤: ê±°ì˜ ì—†ìŒ (FP16)
```

**ACE-Stepì˜ Quantization:**

```
FP32 (ì›ë³¸) â†’ FP16 (ê¸°ë³¸) â†’ INT8 (ì„ íƒì )
  4 bytes      2 bytes       1 byte
```

### Compile (PyTorch 2.0+)

**PyTorch ëª¨ë¸ì„ ìµœì í™”ëœ ê¸°ê³„ ì½”ë“œë¡œ ì»´íŒŒì¼**

```python
# ê¸°ë³¸ í™œì„±í™”
compile = True  # torch.compile() ì‚¬ìš©

# íš¨ê³¼:
# - ì²« ì‹¤í–‰: ëŠë¦¼ (ì»´íŒŒì¼ ì‹œê°„)
# - ì´í›„ ì‹¤í–‰: +20~30% ë¹ ë¦„
# - VRAM: ì•½ê°„ ì¦ê°€
```

**Compile ë™ì‘:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì²« ì‹¤í–‰ (Warm-up)                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚  1. ëª¨ë¸ ê·¸ë˜í”„ ë¶„ì„                       â”‚
â”‚  2. ìµœì í™”ëœ ì»¤ë„ ìƒì„±                     â”‚
â”‚  3. ìºì‹œ ì €ì¥                             â”‚
â”‚  â†’ ì‹œê°„: +5~10ì´ˆ (í•œ ë²ˆë§Œ)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì´í›„ ì‹¤í–‰ (Fast Path)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚  â€¢ ìºì‹œëœ ì»¤ë„ ì¬ì‚¬ìš©                      â”‚
â”‚  â€¢ ë¹ ë¥¸ ìƒì„± (+20~30%)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### GPUë³„ Quantization & Compile ì§€ì›

| GPU | Quantization | Compile | ë¹„ê³  |
|-----|--------------|---------|------|
| **NVIDIA CUDA** | âœ… FP16, INT8 | âœ… | ì™„ì „ ì§€ì› |
| **AMD ROCm** | âœ… FP16 | âš ï¸ ì œí•œì  | TORCH_COMPILE_BACKEND=eager |
| **Intel GPU** | âœ… FP16 | âœ… | ê¸°ë³¸ í™œì„±í™” |
| **MPS (Apple)** | âœ… FP16 | âš ï¸ ì œí•œì  | macOS ìµœì í™” |

---

## ë°°ì¹˜ í¬ê¸° ì¡°ì •

### Batch Sizeë€?

**í•œ ë²ˆì— ìƒì„±í•  ìŒì•… íŠ¸ë™ ê°œìˆ˜**

```python
# Batch Size 1 (ê¸°ë³¸)
generate(prompt, batch_size=1)
# â†’ 1ê°œ íŠ¸ë™ ìƒì„±

# Batch Size 4
generate(prompt, batch_size=4)
# â†’ 4ê°œ íŠ¸ë™ ë™ì‹œ ìƒì„± (ë‹¤ë¥¸ ëœë¤ ì‹œë“œ)
```

### VRAMë³„ ê¶Œì¥ Batch Size

| VRAM | LM ì‚¬ìš© | LM ë¯¸ì‚¬ìš© | ë¹„ê³  |
|------|---------|-----------|------|
| **â‰¤4GB** | - | 1 | ìµœì†Œ VRAM |
| **4-6GB** | - | 1 | DiT only |
| **6-8GB** | 1 | 2 | 0.6B LM |
| **8-12GB** | 2 | 4 | 0.6B LM |
| **12-16GB** | 2 | 4 | 1.7B LM |
| **16-24GB** | 4 | 8 | 4B LM |
| **â‰¥24GB** | 8 | 8 | ë¬´ì œí•œ |

### Batch ìƒì„± ì „ëµ

**ë¹ ë¥¸ ë³€í˜• íƒìƒ‰:**

```python
# 1. ë†’ì€ Batchë¡œ ì—¬ëŸ¬ ë³€í˜• ìƒì„±
results = generate(
    prompt="epic cinematic trailer music",
    batch_size=4,
    seed=None  # ëœë¤ ì‹œë“œ
)

# 2. ê°€ì¥ ì¢‹ì€ ê²°ê³¼ ì„ íƒ
best_result = results[2]

# 3. Coverë¡œ ì„¸ë°€ ì¡°ì •
refined = cover(
    reference_audio=best_result,
    prompt="add more brass and percussion"
)
```

---

## Duration ì œí•œ (VRAMë³„)

### Constrained Decoding

**ACE-Stepì€ GPU Tierì— ë”°ë¼ Durationì„ ìë™ ì œí•œí•©ë‹ˆë‹¤.**

```python
# ë‚´ë¶€ ë¡œì§ ì˜ˆì‹œ
if vram <= 4000:
    max_duration = 180  # 3ë¶„
elif vram <= 6000:
    max_duration = 360  # 6ë¶„
elif vram <= 8000:
    max_duration = 240 if lm_enabled else 360  # 4ë¶„/6ë¶„
# ...
```

### Duration ì´ˆê³¼ ì‹œ ë™ì‘

```python
# ì‚¬ìš©ì ìš”ì²­: 10ë¶„ (600ì´ˆ)
# GPU Tier 3 (6-8GB): ìµœëŒ€ 4ë¶„

# ACE-Step ë™ì‘:
# 1. ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
print("Warning: Requested duration 600s exceeds GPU limit 240s")

# 2. ìë™ìœ¼ë¡œ ì œí•œ
actual_duration = min(requested_duration, max_duration)  # 240ì´ˆ

# 3. ìƒì„±
generate(duration=actual_duration)
```

### Duration vs VRAM ì‚¬ìš©ëŸ‰

**ì˜ˆìƒ VRAM ì‚¬ìš©ëŸ‰ (DiT ìƒì„± ì‹œ):**

```yaml
30ì´ˆ: ~2GB
1ë¶„: ~3GB
2ë¶„: ~4GB
3ë¶„: ~5GB
4ë¶„: ~6GB
6ë¶„: ~8GB
8ë¶„: ~10GB
10ë¶„: ~12GB
```

---

## CUDA, ROCm, Intel GPU, MPS ì„¤ì •

### NVIDIA CUDA

**ê¸°ë³¸ ì„¤ì • (ìë™ ìµœì í™”):**

```bash
# ê¸°ë³¸ ì‹¤í–‰
uv run acestep

# GPU ì„ íƒ (ì—¬ëŸ¬ GPU ìˆì„ ë•Œ)
CUDA_VISIBLE_DEVICES=0 uv run acestep  # ì²« ë²ˆì§¸ GPU
CUDA_VISIBLE_DEVICES=1 uv run acestep  # ë‘ ë²ˆì§¸ GPU
```

**ê³ ê¸‰ CUDA ì„¤ì •:**

```python
# í™˜ê²½ë³€ìˆ˜
export CUDA_LAUNCH_BLOCKING=1  # ë””ë²„ê¹… ì‹œ
export TORCH_CUDA_ARCH_LIST="8.6"  # RTX 30xx ì‹œë¦¬ì¦ˆ

# PyTorch ì„¤ì •
import torch
torch.backends.cudnn.benchmark = True  # ì„±ëŠ¥ í–¥ìƒ
torch.backends.cuda.matmul.allow_tf32 = True  # TF32 í™œì„±í™” (Ampere+)
```

### AMD ROCm

**ROCm ì„¤ì¹˜ ì›Œí¬í”Œë¡œìš°:**

```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv .venv
source .venv/bin/activate

# 2. ROCm PyTorch ì„¤ì¹˜
pip install torch --index-url https://download.pytorch.org/whl/rocm6.0

# 3. ACE-Step ì„¤ì¹˜
pip install -e .

# 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (RDNA3)
export HSA_OVERRIDE_GFX_VERSION=11.0.0  # RX 7900 XT/XTX, RX 9070 XT
export MIOPEN_FIND_MODE=FAST
export TORCH_COMPILE_BACKEND=eager
export ACESTEP_LM_BACKEND=pt

# 5. ì‹¤í–‰
python -m acestep.acestep_v15_pipeline --port 7680
```

**GPUë³„ í™˜ê²½ë³€ìˆ˜:**

| GPU | HSA_OVERRIDE_GFX_VERSION |
|-----|--------------------------|
| **RX 7900 XT/XTX** | 11.0.0 |
| **RX 7800 XT** | 11.0.1 |
| **RX 7600** | 11.0.2 |
| **RX 6900 XT** | 10.3.0 |
| **RX 9070 XT** | 11.0.0 |

**Windows ROCm:**

```batch
REM start_gradio_ui_rocm.bat ì‚¬ìš© (ìë™ í™˜ê²½ë³€ìˆ˜ ì„¤ì •)
start_gradio_ui_rocm.bat
```

### Intel GPU

**ì§€ì› í˜„í™©:**

```yaml
í”Œë«í¼: Windows (í…ŒìŠ¤íŠ¸ë¨)
í…ŒìŠ¤íŠ¸ ê¸°ê¸°: Ultra 9 285H ë‚´ì¥ ê·¸ë˜í”½
PyTorch: 2.8.0 (Intel Extension for PyTorch)
ê¸°ëŠ¥:
  - LLM ì¶”ë¡ : âœ… (0.6B ëª¨ë¸ í…ŒìŠ¤íŠ¸)
  - DiT ìƒì„±: âœ…
  - Offload: âŒ (ê¸°ë³¸ ë¹„í™œì„±í™”)
  - Compile: âœ…
  - Quantization: âœ…
ì œí•œì‚¬í•­:
  - 2ë¶„ ì´ìƒ ìŒì•… ìƒì„± ì‹œ LLM ì¶”ë¡  ì†ë„ ì €í•˜
  - nanovllm ê°€ì† ë¯¸ì§€ì›
```

**Intel GPU ì„¤ì •:**

```bash
# 1. Intel Extension for PyTorch ì„¤ì¹˜
pip install torch torchvision --index-url https://pytorch-extension.intel.com/

# 2. ACE-Step ì‹¤í–‰
uv run acestep --lm_model_path acestep-5Hz-lm-0.6B
```

### Apple MPS (Metal Performance Shaders)

**macOS Apple Silicon ìµœì í™”:**

```bash
# ê¸°ë³¸ ì‹¤í–‰ (ìë™ MPS ê°ì§€)
uv run acestep

# MLX ë°±ì—”ë“œ ì‚¬ìš© (Apple Silicon ë„¤ì´í‹°ë¸Œ)
uv run acestep --backend mlx
```

**MPS vs CPU ì„±ëŠ¥:**

| ê¸°ê¸° | CPU | MPS | ë°°ì† |
|------|-----|-----|------|
| **M1 Pro** | 45ì´ˆ | 12ì´ˆ | 3.75x |
| **M2 Max** | 38ì´ˆ | 9ì´ˆ | 4.22x |
| **M3 Max** | 32ì´ˆ | 7ì´ˆ | 4.57x |

*3ë¶„ ìŒì•… ìƒì„± ê¸°ì¤€

---

## GPU í˜¸í™˜ì„± ê°€ì´ë“œ

### GPU ì§„ë‹¨ ë„êµ¬

```bash
# GPU ê°ì§€ í…ŒìŠ¤íŠ¸
python scripts/check_gpu.py
```

**ì¶œë ¥ ì˜ˆì‹œ:**

```
=== GPU Detection Report ===
GPU Type: NVIDIA
GPU Name: NVIDIA GeForce RTX 3080
VRAM: 12288 MB
CUDA Version: 12.1
PyTorch Version: 2.8.0
Build Type: CUDA

Tier: Tier 5
Recommended LM Model: acestep-5Hz-lm-1.7B
Max Duration: 240s (with LM) / 360s (without LM)
Max Batch Size: 2 (with LM) / 4 (without LM)
```

### ë””ë²„ê·¸ ëª¨ë“œ: GPU ì‹œë®¬ë ˆì´ì…˜

**ë‹¤ë¥¸ VRAM í™˜ê²½ í…ŒìŠ¤íŠ¸:**

```bash
# 4GB GPU ì‹œë®¬ë ˆì´ì…˜ (Tier 1)
MAX_CUDA_VRAM=4 uv run acestep

# 8GB GPU ì‹œë®¬ë ˆì´ì…˜ (Tier 4)
MAX_CUDA_VRAM=8 uv run acestep

# 12GB GPU ì‹œë®¬ë ˆì´ì…˜ (Tier 5)
MAX_CUDA_VRAM=12 uv run acestep

# 16GB GPU ì‹œë®¬ë ˆì´ì…˜ (Tier 6)
MAX_CUDA_VRAM=16 uv run acestep
```

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:**
- âœ… **í…ŒìŠ¤íŠ¸** - ê³ ê¸‰ GPUì—ì„œ ì €ê¸‰ Tier ë™ì‘ í™•ì¸
- âœ… **ê°œë°œ** - GPU Tier ì„¤ì • ê²€ì¦
- âœ… **PR ì œì¶œ ì „** - ë‹¤ì–‘í•œ VRAM í™˜ê²½ í…ŒìŠ¤íŠ¸

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### GPU ê°ì§€ ì•ˆ ë¨ (AMD ROCm)

**ì¦ìƒ:**
```
No GPU detected, running on CPU
```

**í•´ê²° ë°©ë²•:**

```bash
# 1. GPU ì§„ë‹¨ ì‹¤í–‰
python scripts/check_gpu.py

# 2. ROCm ì„¤ì¹˜ í™•ì¸
rocm-smi  # GPU ëª©ë¡ í‘œì‹œë˜ì–´ì•¼ í•¨

# 3. PyTorch ROCm ë¹Œë“œ í™•ì¸
python -c "import torch; print(f'ROCm: {torch.version.hip}')"

# 4. RDNA3 GPU í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export HSA_OVERRIDE_GFX_VERSION=11.0.0

# 5. ì¬ì‹¤í–‰
python -m acestep.acestep_v15_pipeline --port 7680
```

### CPU ì „ìš© PyTorch ì„¤ì¹˜ë¨

**ì¦ìƒ:**
```
Build type: CPU-only
torch.cuda.is_available() = False
```

**í•´ê²° ë°©ë²•:**

```bash
# NVIDIA GPU
pip uninstall torch torchvision torchaudio
pip install torch --index-url https://download.pytorch.org/whl/cu121

# AMD GPU (ROCm)
pip install torch --index-url https://download.pytorch.org/whl/rocm6.0

# í™•ì¸
python -c "import torch; print(torch.cuda.is_available())"  # True
```

### NVIDIA GPU ê°ì§€ ì•ˆ ë¨ (CUDA)

**ì§„ë‹¨ ìˆœì„œ:**

```bash
# 1. NVIDIA ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi

# ì‹¤íŒ¨ ì‹œ: https://www.nvidia.com/download/index.aspx ì—ì„œ ë“œë¼ì´ë²„ ì„¤ì¹˜

# 2. CUDA ë²„ì „ í™•ì¸
python -c "import torch; print(f'CUDA: {torch.version.cuda}')"
nvidia-smi  # "CUDA Version: X.X" í™•ì¸

# 3. PyTorch CUDA ì¬ì„¤ì¹˜
pip uninstall torch torchvision torchaudio
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### WSL2 GPU ì ‘ê·¼ ë¬¸ì œ

**NVIDIA GPU (WSL2):**

```bash
# 1. Windowsì— NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ (WSL2 ë‚´ë¶€ ì•„ë‹˜)
# 2. WSL2ì— CUDA íˆ´í‚· ì„¤ì¹˜
# 3. ê°€ì´ë“œ: https://docs.nvidia.com/cuda/wsl-user-guide/index.html
```

**AMD GPU (WSL2):**
- ROCm WSL2 ì§€ì› ì œí•œì 
- ê¶Œì¥: ë„¤ì´í‹°ë¸Œ Linux ì‚¬ìš© ë˜ëŠ” Windowsì—ì„œ `start_gradio_ui_rocm.bat` ì‚¬ìš©

### Out of Memory (OOM) ì˜¤ë¥˜

**ì¦ìƒ:**
```
torch.cuda.OutOfMemoryError: CUDA out of memory
```

**í•´ê²° ì „ëµ:**

```bash
# 1. DiT ì „ìš© ëª¨ë“œë¡œ ì „í™˜
export ACESTEP_INIT_LLM=false
uv run acestep

# 2. ì‘ì€ LM ëª¨ë¸ ì‚¬ìš©
uv run acestep --lm_model_path acestep-5Hz-lm-0.6B

# 3. CPU Offload í™œì„±í™”
uv run acestep --offload_to_cpu true

# 4. Duration ì¤„ì´ê¸°
# Gradio UIì—ì„œ: Duration 3ë¶„ ì´í•˜ë¡œ ì„¤ì •

# 5. Batch Size ì¤„ì´ê¸°
# Gradio UIì—ì„œ: Batch Size 1ë¡œ ì„¤ì •
```

---

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ìƒì„± ì†ë„ (3ë¶„ ìŒì•… ê¸°ì¤€)

| GPU | VRAM | LM ëª¨ë¸ | Offload | ì‹œê°„ | ì‹¤ì‹œê°„ ë°°ì† |
|-----|------|---------|---------|------|-----------|
| **A100 80GB** | 80GB | 4B | No | 1.8s | 100x |
| **RTX 4090** | 24GB | 4B | No | 4.2s | 42x |
| **RTX 3090** | 24GB | 4B | No | 6.5s | 27x |
| **RTX 4080** | 16GB | 1.7B | No | 8.1s | 22x |
| **RTX 3080** | 12GB | 1.7B | Yes | 12.3s | 14x |
| **RTX 4060 Ti** | 8GB | 0.6B | Yes | 18.7s | 9x |
| **RTX 3060** | 6GB | DiT only | Yes | 15.2s | 11x |

*ì‹¤ì‹œê°„ ë°°ì† = 180s (3ë¶„) / ìƒì„±ì‹œê°„

### VRAM ì‚¬ìš©ëŸ‰ (3ë¶„ ìŒì•… ìƒì„±)

| ì„¤ì • | LM ëª¨ë¸ | Offload | VRAM | ì„¤ëª… |
|------|---------|---------|------|------|
| **ìµœì†Œ** | None | - | 4.2GB | DiT only |
| **ê²½ëŸ‰** | 0.6B | Yes | 6.8GB | ì €VRAM ê¶Œì¥ |
| **í‘œì¤€** | 1.7B | Yes | 9.5GB | ê· í˜•ì¡íŒ ì„¤ì • |
| **ê³ ê¸‰** | 1.7B | No | 11.2GB | ë¹ ë¥¸ ìƒì„± |
| **ìµœëŒ€** | 4B | No | 15.7GB | ìµœê³  í’ˆì§ˆ |

### Durationë³„ ìƒì„± ì‹œê°„ (RTX 3090, 1.7B LM)

| Duration | VRAM | ìƒì„± ì‹œê°„ | ë¹„ê³  |
|----------|------|----------|------|
| **30ì´ˆ** | 3.2GB | 2.1s | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ |
| **1ë¶„** | 4.1GB | 3.5s | ì§§ì€ ë£¨í”„ |
| **2ë¶„** | 5.8GB | 5.2s | í‘œì¤€ ê¸¸ì´ |
| **3ë¶„** | 7.2GB | 6.5s | í’€ì†¡ (ê¶Œì¥) |
| **4ë¶„** | 8.9GB | 8.3s | ê¸´ ê³¡ |
| **6ë¶„** | 12.1GB | 11.7s | í™•ì¥ ë²„ì „ |
| **8ë¶„** | 15.6GB | 15.2s | Tier 6 ì „ìš© |
| **10ë¶„** | 18.9GB | 19.1s | Tier 7 ì „ìš© |

---

## ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬

### GPU ì„¤ì • ê°œì„  PR

**ACE-Stepì€ ì»¤ë®¤ë‹ˆí‹° í”¼ë“œë°±ì„ í™˜ì˜í•©ë‹ˆë‹¤!**

```python
# acestep/gpu_config.py
# í˜„ì¬ ì„¤ì •ì´ ì—¬ëŸ¬ë¶„ì˜ GPUì—ì„œ ì°¨ì„ ì±…ì´ë¼ë©´,
# ë” ë‚˜ì€ íŒŒë¼ë¯¸í„°ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  PRì„ ì œì¶œí•´ì£¼ì„¸ìš”!

# ì˜ˆ: RTX 4060 Ti 8GBì—ì„œ 4ë¶„ ìƒì„± ê°€ëŠ¥ í™•ì¸
if vram == 8000:
    max_duration = 240  # í˜„ì¬: 4ë¶„
    # â†’ í…ŒìŠ¤íŠ¸ ê²°ê³¼ 5ë¶„ë„ ì•ˆì •ì ì´ë¼ë©´
    max_duration = 300  # PR ì œì¶œ!
```

**ê¸°ì—¬ ê°€ì´ë“œë¼ì¸:**

1. **í…ŒìŠ¤íŠ¸ í™˜ê²½ ëª…ì‹œ**
   - GPU ëª¨ë¸
   - VRAM í¬ê¸°
   - OS ë° ë“œë¼ì´ë²„ ë²„ì „

2. **ë°˜ë³µ í…ŒìŠ¤íŠ¸**
   - ìµœì†Œ 10íšŒ ì´ìƒ ìƒì„± í…ŒìŠ¤íŠ¸
   - OOM ì—†ì´ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘ í™•ì¸

3. **PR ì œì¶œ**
   - `acestep/gpu_config.py` ìˆ˜ì •
   - í…ŒìŠ¤íŠ¸ ê²°ê³¼ í¬í•¨
   - ì»¤ë®¤ë‹ˆí‹° ê°œì„ ì— ê¸°ì—¬!

---

## ë‹¤ìŒ ë‹¨ê³„

**ì´ ê°€ì´ë“œì—ì„œëŠ”:**
- âœ… VRAMë³„ ìµœì í™” ì „ëµ ì´í•´
- âœ… DiT ì „ìš© vs LLM ëª¨ë“œ ë¹„êµ
- âœ… CPU Offload, Quantization, Compile í™œìš©
- âœ… ë°°ì¹˜ í¬ê¸° ë° Duration ì œí•œ íŒŒì•…
- âœ… CUDA, ROCm, Intel GPU, MPS ì„¤ì •
- âœ… GPU í˜¸í™˜ì„± ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

**ë‹¤ìŒ ê¸€ì—ì„œëŠ”:**
- ğŸ‰ **ACE-Step 1.5 ê²°ë¡  ë° í™œìš©**
- ğŸ¯ ì‹¤ì œ í™œìš© ì‹œë‚˜ë¦¬ì˜¤ (ì½˜í…ì¸  ì œì‘, ìŒì•… í”„ë¡œë“€ì‹±)
- ğŸŒ ì»¤ë®¤ë‹ˆí‹° ë¦¬ì†ŒìŠ¤ ë° ë‹¤ìŒ ë‹¨ê³„
- ğŸµ "ìŒì•…ì„ Play(ì—°ì£¼/ë†€ì´)í•˜ì„¸ìš”" ìµœì¢… ë©”ì‹œì§€

---

*GPU ìµœì í™”ë¥¼ í†µí•´ ACE-Step 1.5ì˜ ì„±ëŠ¥ì„ ìµœëŒ€í•œ ëŒì–´ë‚´ì„¸ìš”. ì—¬ëŸ¬ë¶„ì˜ í•˜ë“œì›¨ì–´ì— ë§ëŠ” ìµœì  ì„¤ì •ì„ ì°¾ëŠ” ê²ƒì´ ì°½ì˜ì  ì›Œí¬í”Œë¡œìš°ì˜ ì‹œì‘ì…ë‹ˆë‹¤!*
