---
layout: post
title: "effGen ì™„ë²½ ê°€ì´ë“œ (02) - ì„¤ì¹˜ ë° ë¹ ë¥¸ ì‹œì‘"
date: 2026-02-09
permalink: /effgen-guide-02-quick-start/
author: Gaurav Srivastava
categories: [AI ì—ì´ì „íŠ¸, Python]
tags: [SLM, AI Agent, Small Language Models, Tool Use, Multi-Agent, Python, Qwen, vLLM]
original_url: "https://github.com/ctrl-gaurav/effGen"
excerpt: "effGen í”„ë ˆì„ì›Œí¬ ì„¤ì¹˜ë¶€í„° ì²« AI ì—ì´ì „íŠ¸ ìƒì„±ê¹Œì§€ ë‹¨ê³„ë³„ ê°€ì´ë“œ"
---

# effGen ì™„ë²½ ê°€ì´ë“œ (02) - ì„¤ì¹˜ ë° ë¹ ë¥¸ ì‹œì‘

## ëª©ì°¨
1. [ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­](#ì‹œìŠ¤í…œ-ìš”êµ¬ì‚¬í•­)
2. [ì„¤ì¹˜ ë°©ë²•](#ì„¤ì¹˜-ë°©ë²•)
3. [CLI ì‚¬ìš©ë²•](#cli-ì‚¬ìš©ë²•)
4. [Python API ê¸°ë³¸](#python-api-ê¸°ë³¸)
5. [ì²« ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°](#ì²«-ì—ì´ì „íŠ¸-ë§Œë“¤ê¸°)
6. [ë©€í‹°-íˆ´ ì—ì´ì „íŠ¸](#ë©€í‹°-íˆ´-ì—ì´ì „íŠ¸)
7. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

---

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

effGenì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ìµœì†Œ ë° ê¶Œì¥ ì‚¬ì–‘ì…ë‹ˆë‹¤.

### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­

| êµ¬ì„±ìš”ì†Œ | ìµœì†Œ ë²„ì „ | ê¶Œì¥ ë²„ì „ |
|---------|----------|-----------|
| Python | 3.8+ | 3.10+ |
| PyTorch | 2.0+ | 2.3+ |
| CUDA (GPU ì‚¬ìš© ì‹œ) | 11.8+ | 12.1+ |
| Docker (ìƒŒë“œë°•ìŠ¤ìš©) | 20.10+ | 24.0+ |

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

**CPU ì „ìš© (ê¸°ë³¸ ì‚¬ìš©)**
- RAM: 8GB ì´ìƒ
- ì €ì¥ê³µê°„: 10GB ì´ìƒ
- ì†ë„: ~5-10 tokens/sec (1.5B ëª¨ë¸)

**GPU ê°€ì† (ê¶Œì¥)**

| ëª¨ë¸ í¬ê¸° | VRAM | ê¶Œì¥ GPU | ì¶”ë¡  ì†ë„ |
|----------|------|----------|-----------|
| 1.5B (4bit) | 2-3GB | RTX 3060, T4 | ~45 tokens/sec |
| 3B (4bit) | 4-5GB | RTX 3060 Ti, RTX 4060 | ~35 tokens/sec |
| 7B (4bit) | 6-8GB | RTX 3080, RTX 4070 | ~25 tokens/sec |
| 14B (4bit) | 12-16GB | RTX 4090, A100 | ~15 tokens/sec |

**ì–‘ìí™” ì˜µì…˜ë³„ ë©”ëª¨ë¦¬**

```python
# Qwen2.5-1.5B ëª¨ë¸ ê¸°ì¤€
FP16:  ~3GB VRAM   (ìµœê³  í’ˆì§ˆ, ëŠë¦¼)
INT8:  ~2GB VRAM   (ê· í˜•)
INT4:  ~1.5GB VRAM (ê¶Œì¥, ì†ë„/í’ˆì§ˆ ë°¸ëŸ°ìŠ¤)
INT2:  ~1GB VRAM   (ìµœëŒ€ ì••ì¶•, í’ˆì§ˆ ì €í•˜)
```

### ì§€ì› ìš´ì˜ì²´ì œ

- **Linux**: Ubuntu 20.04+, Debian 11+, CentOS 8+ (ì™„ì „ ì§€ì›)
- **macOS**: 11.0+ (Metal ê°€ì† ì§€ì›)
- **Windows**: 10/11 (WSL2 ê¶Œì¥)

---

## ì„¤ì¹˜ ë°©ë²•

effGenì€ 3ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë°©ë²• 1: PyPI ì„¤ì¹˜ (ê¶Œì¥)

ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì…ë‹ˆë‹¤:

```bash
# ê¸°ë³¸ ì„¤ì¹˜
pip install effgen

# íŠ¹ì • ë²„ì „ ì„¤ì¹˜
pip install effgen==0.0.2

# ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade effgen
```

**ì„¤ì¹˜ í™•ì¸**:

```bash
effgen --version
# effgen, version 0.0.2
```

### ë°©ë²• 2: vLLM ë°±ì—”ë“œ í¬í•¨ ì„¤ì¹˜

ê³ ì† ì¶”ë¡ ì„ ìœ„í•œ vLLM ë°±ì—”ë“œë¥¼ í•¨ê»˜ ì„¤ì¹˜:

```bash
# vLLM í¬í•¨ ì„¤ì¹˜
pip install effgen[vllm]

# ë˜ëŠ” ê°œë³„ ì„¤ì¹˜
pip install effgen
pip install vllm
```

**vLLM ì‚¬ìš© ì‹œ ì¥ì **:
- 2-4ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„
- PagedAttentionìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ í–¥ìƒ
- ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

**ë²¤ì¹˜ë§ˆí¬ ë¹„êµ** (Qwen2.5-7B, RTX 4090):

```
Backend     | Tokens/sec | Latency (first token)
------------|------------|----------------------
Transformers|     25     |        1.2s
vLLM        |     95     |        0.3s
```

### ë°©ë²• 3: ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜ (ê°œë°œììš©)

ìµœì‹  ê°œë°œ ë²„ì „ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ê¸°ì—¬í•˜ê³  ì‹¶ë‹¤ë©´:

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/ctrl-gaurav/effGen.git
cd effGen

# ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x install.sh
./install.sh

# ë˜ëŠ” ìˆ˜ë™ ì„¤ì¹˜
pip install -e .
```

**ê°œë°œ ëª¨ë“œ ì„¤ì¹˜**:

```bash
# ê°œë°œ ì˜ì¡´ì„± í¬í•¨
pip install -e ".[dev]"

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/

# ë¦°íŒ…
ruff check .
```

### ì„ íƒì  ì˜ì¡´ì„±

ì¶”ê°€ ê¸°ëŠ¥ì„ ìœ„í•œ ì„ íƒì  íŒ¨í‚¤ì§€:

```bash
# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ (Retrieval ë„êµ¬ìš©)
pip install chromadb faiss-cpu

# ì´ë¯¸ì§€ ì²˜ë¦¬ (ë©€í‹°ëª¨ë‹¬ìš©)
pip install pillow transformers[vision]

# ê³ ê¸‰ NLP
pip install spacy
python -m spacy download en_core_web_sm

# ë¬¸ì„œ íŒŒì‹±
pip install pypdf docx2txt
```

---

## CLI ì‚¬ìš©ë²•

effGenì€ ê°•ë ¥í•œ ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ê¸°ë³¸ ëª…ë ¹ì–´

#### 1. `effgen run` - ë‹¨ì¼ ì‘ì—… ì‹¤í–‰

```bash
# ê¸°ë³¸ ì‚¬ìš©
effgen run "What is the capital of France?"

# ëª¨ë¸ ì§€ì •
effgen run "Calculate 15% of 250" --model Qwen/Qwen2.5-1.5B-Instruct

# ë„êµ¬ ì§€ì •
effgen run "Search for latest AI news" --tools WebSearch Calculator

# ì¶œë ¥ í˜•ì‹ ì§€ì •
effgen run "List prime numbers up to 50" --output json

# ìƒì„¸ ë¡œê·¸
effgen run "Complex task" --verbose
```

**ì‹¤í–‰ ì˜ˆì‹œ**:

```bash
$ effgen run "Calculate the square root of 144 and add 20"

[effGen] Loading model: Qwen/Qwen2.5-1.5B-Instruct
[effGen] Initializing tools: Calculator
[effGen] Processing query...

Thought: I need to calculate sqrt(144) first, then add 20.
Action: Calculator
Action Input: sqrt(144)
Observation: 12.0

Thought: Now I'll add 20 to the result.
Action: Calculator
Action Input: 12 + 20
Observation: 32.0

Final Answer: The result is 32.0
```

#### 2. `effgen chat` - ëŒ€í™”í˜• ëª¨ë“œ

```bash
# ê¸°ë³¸ ì±„íŒ…
effgen chat

# ëª¨ë¸ ë° ë„êµ¬ ì§€ì •
effgen chat --model Qwen/Qwen2.5-3B-Instruct --tools Calculator WebSearch FileOps

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í…€
effgen chat --system-prompt "You are a Python programming expert."

# ë©”ëª¨ë¦¬ í™œì„±í™”
effgen chat --memory ./chat_history.db
```

**ì±„íŒ… ì„¸ì…˜ ì˜ˆì‹œ**:

```
$ effgen chat --tools Calculator WebSearch

[effGen] Starting interactive chat session
[effGen] Type 'exit' to quit, 'clear' to reset conversation

You: What's the current Bitcoin price?

Agent: [Thinking] I need to search for the current Bitcoin price.
[Tool: WebSearch] Query: "Bitcoin price USD now"
[Result] Bitcoin is currently trading at $45,234.56

The current Bitcoin price is approximately $45,234.56 USD.

You: Calculate 15% of that

Agent: [Thinking] I'll use the calculator to find 15% of 45234.56
[Tool: Calculator] 45234.56 * 0.15
[Result] 6785.184

15% of $45,234.56 is $6,785.18.

You: exit

[effGen] Conversation saved to ./chat_history.db
```

#### 3. `effgen serve` - API ì„œë²„ ì‹¤í–‰

REST API ì„œë²„ë¡œ effGenì„ ë°°í¬:

```bash
# ê¸°ë³¸ ì„œë²„ ì‹¤í–‰ (í¬íŠ¸ 8000)
effgen serve

# í¬íŠ¸ ë° í˜¸ìŠ¤íŠ¸ ì§€ì •
effgen serve --host 0.0.0.0 --port 8080

# ì›Œì»¤ ìˆ˜ ì§€ì • (í”„ë¡œë•ì…˜)
effgen serve --workers 4

# íŠ¹ì • ëª¨ë¸ë¡œ ì„œë²„ ì‹œì‘
effgen serve --model Qwen/Qwen2.5-7B-Instruct --tools all
```

**API ì‚¬ìš© ì˜ˆì‹œ**:

```bash
# ì„œë²„ ì‹œì‘
$ effgen serve --port 8000

# ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ API í˜¸ì¶œ
$ curl -X POST http://localhost:8000/v1/agent/run \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Calculate the factorial of 10",
    "tools": ["Calculator"]
  }'

# ì‘ë‹µ
{
  "result": "The factorial of 10 is 3,628,800",
  "steps": [
    {"tool": "Calculator", "input": "10!", "output": "3628800"}
  ],
  "execution_time": 1.23
}
```

#### 4. `effgen` - ëŒ€í™”í˜• ì„¤ì • ë§ˆë²•ì‚¬

ì¸ì ì—†ì´ ì‹¤í–‰í•˜ë©´ ëŒ€í™”í˜• ì„¤ì • ì‹œì‘:

```bash
$ effgen

Welcome to effGen! Let's set up your first agent.

? Select a model:
  > Qwen/Qwen2.5-1.5B-Instruct (Fast, 2GB VRAM)
    Qwen/Qwen2.5-3B-Instruct (Balanced, 4GB VRAM)
    Qwen/Qwen2.5-7B-Instruct (Powerful, 8GB VRAM)
    Custom model path

? Select tools (Space to select, Enter to confirm):
  [x] Calculator
  [x] WebSearch
  [ ] CodeExecutor
  [x] FileOps
  [ ] PythonREPL

? Enable memory? (Y/n): Y
? Memory storage path: ./effgen_memory.db

? Start in chat mode? (Y/n): Y

[effGen] Initializing agent with your settings...
[effGen] Ready! Starting chat session.
```

---

## Python API ê¸°ë³¸

í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ effGen ì‚¬ìš©í•˜ê¸°.

### ê¸°ë³¸ êµ¬ì¡°

ëª¨ë“  effGen í”„ë¡œê·¸ë¨ì€ ë‹¤ìŒ íŒ¨í„´ì„ ë”°ë¦…ë‹ˆë‹¤:

```python
from effgen import Agent, load_model
from effgen.core.agent import AgentConfig
from effgen.tools.builtin import Tool1, Tool2

# 1. ëª¨ë¸ ë¡œë“œ
model = load_model("model_name")

# 2. ë„êµ¬ ì´ˆê¸°í™”
tools = [Tool1(), Tool2()]

# 3. ì—ì´ì „íŠ¸ ì„¤ì •
config = AgentConfig(
    name="agent_name",
    model=model,
    tools=tools,
    system_prompt="Custom instructions"
)

# 4. ì—ì´ì „íŠ¸ ìƒì„±
agent = Agent(config=config)

# 5. ì‹¤í–‰
result = agent.run("Your query here")
```

### ëª¨ë¸ ë¡œë“œ ì˜µì…˜

```python
from effgen import load_model

# ê¸°ë³¸ ë¡œë“œ (ìë™ ì–‘ìí™”)
model = load_model("Qwen/Qwen2.5-1.5B-Instruct")

# ëª…ì‹œì  ì–‘ìí™”
model = load_model(
    "Qwen/Qwen2.5-3B-Instruct",
    quantization="4bit"  # "8bit", "4bit", "2bit", None
)

# GPU ì¥ì¹˜ ì§€ì •
model = load_model(
    "Qwen/Qwen2.5-7B-Instruct",
    device="cuda:0"  # ë˜ëŠ” "cuda:1", "cpu", "mps"
)

# vLLM ë°±ì—”ë“œ ì‚¬ìš©
model = load_model(
    "Qwen/Qwen2.5-7B-Instruct",
    backend="vllm",
    tensor_parallel_size=2  # ë©€í‹°GPU
)

# ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ
model = load_model(
    "/path/to/local/model",
    trust_remote_code=True
)

# ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •
model = load_model(
    "Qwen/Qwen2.5-1.5B-Instruct",
    generation_config={
        "temperature": 0.7,
        "top_p": 0.9,
        "max_new_tokens": 512,
        "do_sample": True
    }
)
```

### AgentConfig ì˜µì…˜

```python
from effgen.core.agent import AgentConfig

config = AgentConfig(
    # í•„ìˆ˜
    name="my_agent",
    model=model,

    # ë„êµ¬
    tools=[Calculator(), WebSearch()],
    max_tool_calls=10,  # ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜

    # í”„ë¡¬í”„íŠ¸
    system_prompt="Custom system instructions",
    user_prompt_template="User: {query}\nAssistant:",

    # ë©”ëª¨ë¦¬
    memory=UnifiedMemory(),
    enable_memory_retrieval=True,

    # ì‹¤í–‰
    max_iterations=15,  # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    timeout=300,        # íƒ€ì„ì•„ì›ƒ (ì´ˆ)

    # ë¶„í•´
    enable_decomposition=True,
    decomposition_threshold=0.7,  # ë³µì¡ë„ ì„ê³„ê°’

    # ë©€í‹°ì—ì´ì „íŠ¸
    enable_sub_agents=True,
    max_sub_agents=3,

    # ë¡œê¹…
    verbose=True,
    log_file="./agent.log"
)
```

---

## ì²« ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°

ë‹¨ê³„ë³„ë¡œ ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤.

### ì˜ˆì œ 1: Calculator ì—ì´ì „íŠ¸

**í”„ë¡œì íŠ¸ êµ¬ì¡°**:
```
my_first_agent/
â”œâ”€â”€ agent.py
â””â”€â”€ requirements.txt
```

**requirements.txt**:
```
effgen>=0.0.2
torch>=2.0.0
```

**agent.py**:
```python
"""
ì²« ë²ˆì§¸ effGen ì—ì´ì „íŠ¸ - ê³„ì‚°ê¸° ë„ìš°ë¯¸
"""

from effgen import Agent, load_model
from effgen.core.agent import AgentConfig
from effgen.tools.builtin import Calculator

def main():
    # 1. ëª¨ë¸ ë¡œë“œ (1.5B ëª¨ë¸, 4bit ì–‘ìí™”)
    print("ğŸ“¦ Loading model...")
    model = load_model(
        "Qwen/Qwen2.5-1.5B-Instruct",
        quantization="4bit",
        device="auto"  # ìë™ìœ¼ë¡œ GPU ë˜ëŠ” CPU ì„ íƒ
    )

    # 2. ë„êµ¬ ì´ˆê¸°í™”
    calculator = Calculator()

    # 3. ì—ì´ì „íŠ¸ ì„¤ì •
    config = AgentConfig(
        name="calculator_assistant",
        model=model,
        tools=[calculator],
        system_prompt=(
            "You are a helpful math assistant. "
            "Use the Calculator tool to perform accurate calculations. "
            "Always show your work step by step."
        ),
        max_iterations=5,
        verbose=True
    )

    # 4. ì—ì´ì „íŠ¸ ìƒì„±
    agent = Agent(config=config)

    # 5. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "Calculate 15% tip on a $85.50 bill",
        "What is the square root of 2025?",
        "If I invest $10,000 at 5% annual interest, how much will I have after 3 years?",
    ]

    print("\n" + "="*60)
    print("ğŸ¤– Calculator Agent Ready!")
    print("="*60 + "\n")

    for i, query in enumerate(test_queries, 1):
        print(f"\n{'â”€'*60}")
        print(f"Query {i}: {query}")
        print('â”€'*60)

        result = agent.run(query)

        print(f"\nâœ… Result: {result}")
        print()

    # 6. ëŒ€í™”í˜• ëª¨ë“œ
    print("\n" + "="*60)
    print("Entering interactive mode. Type 'quit' to exit.")
    print("="*60 + "\n")

    while True:
        try:
            user_input = input("You: ").strip()

            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ Goodbye!")
                break

            if not user_input:
                continue

            result = agent.run(user_input)
            print(f"\nAgent: {result}\n")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}\n")

if __name__ == "__main__":
    main()
```

**ì‹¤í–‰**:

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# ì‹¤í–‰
python agent.py
```

**ì˜ˆìƒ ì¶œë ¥**:

```
ğŸ“¦ Loading model...
[effGen] Downloading Qwen/Qwen2.5-1.5B-Instruct...
[effGen] Model loaded successfully (1.2GB)

============================================================
ğŸ¤– Calculator Agent Ready!
============================================================

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query 1: Calculate 15% tip on a $85.50 bill
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[Agent] Thought: I need to calculate 15% of $85.50
[Agent] Action: Calculator
[Agent] Action Input: 85.50 * 0.15
[Agent] Observation: 12.825
[Agent] Thought: The tip amount is $12.83 (rounded)

âœ… Result: The 15% tip on a $85.50 bill is $12.83

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query 2: What is the square root of 2025?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[Agent] Thought: I'll use the calculator to find sqrt(2025)
[Agent] Action: Calculator
[Agent] Action Input: sqrt(2025)
[Agent] Observation: 45.0

âœ… Result: The square root of 2025 is 45

...
```

---

## ë©€í‹°-íˆ´ ì—ì´ì „íŠ¸

ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê³ ê¸‰ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤.

### ì˜ˆì œ 2: ì—°êµ¬ ë³´ì¡° ì—ì´ì „íŠ¸

```python
"""
ë©€í‹°-íˆ´ ì—ì´ì „íŠ¸ - ì—°êµ¬ ë° ë¶„ì„ ë³´ì¡°
"""

from effgen import Agent, load_model
from effgen.core.agent import AgentConfig
from effgen.tools.builtin import (
    Calculator,
    WebSearch,
    FileOps,
    PythonREPL
)
from effgen.memory import UnifiedMemory

def create_research_agent():
    """ì—°êµ¬ ë³´ì¡° ì—ì´ì „íŠ¸ ìƒì„±"""

    # ëª¨ë¸ ë¡œë“œ (ë” í° ëª¨ë¸ ì‚¬ìš©)
    model = load_model(
        "Qwen/Qwen2.5-3B-Instruct",
        quantization="4bit",
        generation_config={
            "temperature": 0.3,  # ë” ì¼ê´€ëœ ì¶œë ¥
            "top_p": 0.9,
            "max_new_tokens": 1024
        }
    )

    # ë„êµ¬ë“¤ ì´ˆê¸°í™”
    calculator = Calculator()
    web_search = WebSearch(max_results=5)
    file_ops = FileOps(base_dir="./research_output")
    python_repl = PythonREPL()

    # ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
    memory = UnifiedMemory(
        short_term_size=20,
        long_term_storage="./research_memory.db",
        vector_store="chromadb"
    )

    # ì—ì´ì „íŠ¸ ì„¤ì •
    config = AgentConfig(
        name="research_assistant",
        model=model,
        tools=[calculator, web_search, file_ops, python_repl],
        memory=memory,
        system_prompt="""You are an expert research assistant with access to:
        - Calculator: for mathematical computations
        - WebSearch: for finding information online
        - FileOps: for reading and writing files
        - PythonREPL: for data analysis and visualization

        When given a research task:
        1. Search for relevant information
        2. Analyze the data using Python if needed
        3. Perform calculations if necessary
        4. Save results to files
        5. Provide a comprehensive summary

        Always cite sources and show your work.""",
        max_iterations=20,
        enable_decomposition=True,
        verbose=True
    )

    return Agent(config=config)

def example_research_task():
    """ì˜ˆì œ ì—°êµ¬ ì‘ì—…"""

    agent = create_research_agent()

    # ë³µì¡í•œ ë©€í‹°ìŠ¤í… ì‘ì—…
    query = """
    Research task: Analyze the growth of AI agent frameworks in 2025-2026.

    Steps:
    1. Search for popular AI agent frameworks released in 2025-2026
    2. Compare their GitHub stars and activity
    3. Calculate growth percentages
    4. Create a simple visualization (save as plot.png)
    5. Write a summary report (save as report.md)
    """

    print("ğŸ”¬ Starting research task...\n")
    result = agent.run(query)

    print("\n" + "="*60)
    print("ğŸ“Š Research Complete!")
    print("="*60)
    print(f"\n{result}\n")

# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    example_research_task()
```

**ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ**:

```python
ğŸ”¬ Starting research task...

[Decomposition] Breaking down complex task into 5 subtasks:
  â”œâ”€ Task 1: WebSearch for AI agent frameworks 2025-2026
  â”œâ”€ Task 2: Extract GitHub statistics (depends on 1)
  â”œâ”€ Task 3: Calculate growth metrics (depends on 2)
  â”œâ”€ Task 4: Create visualization (depends on 3)
  â””â”€ Task 5: Write report (depends on 4)

[Executing Task 1: WebSearch]
[Tool: WebSearch] Query: "AI agent frameworks 2025 2026 GitHub"
[Result] Found 5 relevant frameworks:
  - effGen (2026): 1.2k stars
  - LangGraph (2025): 8.5k stars
  - AutoGen (2025): 15k stars
  - CrewAI (2025): 6.3k stars
  - AgentOps (2026): 890 stars

[Executing Task 2: Extract statistics]
[Tool: WebSearch] Fetching detailed GitHub stats...
[Result] Data collected for all frameworks

[Executing Task 3: Calculate growth]
[Tool: Calculator] Computing growth percentages...
[Result] Average monthly growth: 23.4%

[Executing Task 4: Visualization]
[Tool: PythonREPL] Creating bar chart...
```python
import matplotlib.pyplot as plt

frameworks = ['effGen', 'LangGraph', 'AutoGen', 'CrewAI', 'AgentOps']
stars = [1200, 8500, 15000, 6300, 890]

plt.figure(figsize=(10, 6))
plt.bar(frameworks, stars, color='steelblue')
plt.title('AI Agent Frameworks - GitHub Stars (2025-2026)')
plt.ylabel('Stars')
plt.savefig('./research_output/plot.png')
```
[Result] Chart saved to ./research_output/plot.png

[Executing Task 5: Write report]
[Tool: FileOps] Writing to report.md...
[Result] Report saved

============================================================
ğŸ“Š Research Complete!
============================================================

Summary: Successfully analyzed 5 AI agent frameworks from 2025-2026.
Key findings:
- AutoGen leads with 15k stars
- Average monthly growth: 23.4%
- effGen and AgentOps are newer but showing strong growth
- Full report saved to ./research_output/report.md
- Visualization saved to ./research_output/plot.png

Sources:
- GitHub API
- DuckDuckGo Search
```

---

## ë¬¸ì œ í•´ê²°

ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²° ë°©ë²•ì…ë‹ˆë‹¤.

### 1. CUDA Out of Memory

**ì¦ìƒ**:
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**í•´ê²°**:
```python
# ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
model = load_model("Qwen/Qwen2.5-1.5B-Instruct")  # ëŒ€ì‹  3B

# ë” ê°•í•œ ì–‘ìí™”
model = load_model(
    "Qwen/Qwen2.5-3B-Instruct",
    quantization="4bit"  # ë˜ëŠ” "2bit"
)

# CPUë¡œ í´ë°±
model = load_model(
    "Qwen/Qwen2.5-1.5B-Instruct",
    device="cpu"
)
```

### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŠë¦¼

**ì¦ìƒ**: Hugging Faceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ ë§¤ìš° ëŠë¦¼

**í•´ê²°**:
```bash
# ë¯¸ëŸ¬ ì‚¬ìš© (ì¤‘êµ­/ì•„ì‹œì•„)
export HF_ENDPOINT=https://hf-mirror.com
pip install effgen

# ë˜ëŠ” ì§ì ‘ ë‹¤ìš´ë¡œë“œ í›„ ë¡œì»¬ ê²½ë¡œ ì‚¬ìš©
huggingface-cli download Qwen/Qwen2.5-1.5B-Instruct --local-dir ./models/qwen-1.5b

# Pythonì—ì„œ
model = load_model("./models/qwen-1.5b")
```

### 3. ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨

**ì¦ìƒ**: ì—ì´ì „íŠ¸ê°€ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê±°ë‚˜ ì˜ëª» í˜¸ì¶œ

**í•´ê²°**:
```python
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œì  ì§€ì¹¨ ì¶”ê°€
config = AgentConfig(
    system_prompt="""You MUST use tools to answer questions.

Available tools:
- Calculator: Use for ANY mathematical calculation
- WebSearch: Use to find current information
- FileOps: Use to read/write files

Format:
Thought: [your reasoning]
Action: [tool name]
Action Input: [input to tool]
""",
    # ë„êµ¬ ì‚¬ìš© ê°•ì œ
    force_tool_use=True
)
```

### 4. Docker ìƒŒë“œë°•ìŠ¤ ì˜¤ë¥˜

**ì¦ìƒ**: `CodeExecutor` ì‚¬ìš© ì‹œ Docker ê´€ë ¨ ì˜¤ë¥˜

**í•´ê²°**:
```bash
# Docker ì„¤ì¹˜ í™•ì¸
docker --version

# Docker ë°ëª¬ ì‹œì‘
sudo systemctl start docker

# ì‚¬ìš©ìë¥¼ docker ê·¸ë£¹ì— ì¶”ê°€
sudo usermod -aG docker $USER

# ë˜ëŠ” ìƒŒë“œë°•ìŠ¤ ë¹„í™œì„±í™” (ì£¼ì˜!)
```

```python
executor = CodeExecutor(sandbox=False)  # ë¡œì»¬ ì‹¤í–‰
```

### 5. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜

**ì¦ìƒ**: ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€

**í•´ê²°**:
```python
# ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
memory = UnifiedMemory(
    short_term_size=10,  # ì¤„ì´ê¸°
    enable_cleanup=True,
    cleanup_interval=100  # 100 ëŒ€í™”ë§ˆë‹¤ ì •ë¦¬
)

# ë˜ëŠ” ìˆ˜ë™ ì •ë¦¬
agent.memory.clear_short_term()
agent.memory.compact_long_term()
```

### 6. vLLM ì„¤ì¹˜ ì˜¤ë¥˜

**ì¦ìƒ**: `pip install effgen[vllm]` ì‹¤íŒ¨

**í•´ê²°**:
```bash
# Python ë²„ì „ í™•ì¸ (3.8-3.11 ì§€ì›)
python --version

# CUDA ë²„ì „ í™•ì¸
nvcc --version

# í˜¸í™˜ë˜ëŠ” ë²„ì „ ì„¤ì¹˜
pip install vllm==0.3.1  # íŠ¹ì • ë²„ì „

# ë¹Œë“œ ì˜ì¡´ì„±
pip install ninja packaging
```

---

## ë‹¤ìŒ ë‹¨ê³„

ì´ì œ effGenì„ ì„¤ì¹˜í•˜ê³  ê¸°ë³¸ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì±•í„°ì—ì„œëŠ” effGenì˜ ë‚´ë¶€ ì•„í‚¤í…ì²˜ë¥¼ ê¹Šì´ ìˆê²Œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

**[ë‹¤ìŒ: ì±•í„° 03 - í•µì‹¬ ì•„í‚¤í…ì²˜ â†’](/effgen-guide-03-architecture/)**

---

## ì°¸ê³  ìë£Œ

1. [effGen ê³µì‹ ë¬¸ì„œ](https://effgen.org/docs)
2. [Qwen2.5 ëª¨ë¸ ì¹´ë“œ](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct)
3. [vLLM ë¬¸ì„œ](https://docs.vllm.ai/)
4. [PyTorch ì„¤ì¹˜ ê°€ì´ë“œ](https://pytorch.org/get-started/locally/)

---

**ì „ì²´ ê°€ì´ë“œ ëª©ì°¨**:
- [01ì¥: ì†Œê°œ ë° ê°œìš”](/effgen-guide-01-intro/)
- [02ì¥: ì„¤ì¹˜ ë° ë¹ ë¥¸ ì‹œì‘](/effgen-guide-02-quick-start/) â† í˜„ì¬ ë¬¸ì„œ
- [03ì¥: í•µì‹¬ ì•„í‚¤í…ì²˜](/effgen-guide-03-architecture/)