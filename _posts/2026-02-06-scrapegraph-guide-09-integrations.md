---
layout: post
title: "ScrapeGraphAI ì™„ë²½ ê°€ì´ë“œ (9) - í†µí•© ë° í™•ì¥"
date: 2026-02-06
permalink: /scrapegraph-guide-09-integrations/
author: ScrapeGraphAI Team
categories: [AI ë„êµ¬, ì›¹ ìŠ¤í¬ë˜í•‘]
tags: [ScrapeGraphAI, Integration, API, SDK, Langchain, n8n, Zapier]
original_url: "https://github.com/ScrapeGraphAI/Scrapegraph-ai"
excerpt: "ScrapeGraphAIë¥¼ ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ ë° í”Œë«í¼ê³¼ í†µí•©í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤."
---

## í†µí•© ê°œìš”

ScrapeGraphAIëŠ” ë‹¤ìŒê³¼ ê°™ì€ í†µí•©ì„ ì œê³µí•©ë‹ˆë‹¤:

- **API/SDK**: Python SDK, Node.js SDK
- **LLM í”„ë ˆì„ì›Œí¬**: Langchain, LlamaIndex, CrewAI, Agno
- **ë…¸ì½”ë“œ í”Œë«í¼**: n8n, Zapier, Pipedream, Bubble
- **MCP ì„œë²„**: Claude Desktop í†µí•©

## ê³µì‹ API ì‚¬ìš©

### API ê°€ì…

1. [ScrapeGraphAI Dashboard](https://dashboard.scrapegraphai.com/login) ì ‘ì†
2. ê³„ì • ìƒì„± ë° API í‚¤ ë°œê¸‰
3. í¬ë ˆë”§ êµ¬ë§¤ (ë¬´ë£Œ í‹°ì–´ ì œê³µ)

### Python SDK

#### ì„¤ì¹˜

```bash
pip install scrapegraph-py
```

#### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from scrapegraph_py import Client

client = Client(api_key="sgai-...")

# SmartScraper ì‹¤í–‰
result = client.smartscraper(
    website_url="https://example.com",
    user_prompt="Extract product names and prices"
)

print(result)
```

#### ê³ ê¸‰ ì‚¬ìš©

```python
# ì—¬ëŸ¬ URL ìŠ¤í¬ë˜í•‘
results = client.smartscraper(
    website_url=[
        "https://site1.com",
        "https://site2.com",
        "https://site3.com"
    ],
    user_prompt="Extract company info",
    output_schema={
        "type": "object",
        "properties": {
            "company": {"type": "string"},
            "industry": {"type": "string"}
        }
    }
)
```

### Node.js SDK

#### ì„¤ì¹˜

```bash
npm install scrapegraph-js
```

#### ì‚¬ìš© ì˜ˆì œ

```javascript
const { Client } = require('scrapegraph-js');

const client = new Client({ apiKey: 'sgai-...' });

async function scrape() {
    const result = await client.smartscraper({
        websiteUrl: 'https://example.com',
        userPrompt: 'Extract all article titles'
    });

    console.log(result);
}

scrape();
```

### REST API

#### cURL ì˜ˆì œ

```bash
curl -X POST https://api.scrapegraphai.com/v1/smartscraper \
  -H "Authorization: Bearer sgai-..." \
  -H "Content-Type: application/json" \
  -d '{
    "website_url": "https://example.com",
    "user_prompt": "Extract product information"
  }'
```

#### Python requests

```python
import requests

response = requests.post(
    "https://api.scrapegraphai.com/v1/smartscraper",
    headers={
        "Authorization": "Bearer sgai-...",
        "Content-Type": "application/json"
    },
    json={
        "website_url": "https://example.com",
        "user_prompt": "Extract data"
    }
)

result = response.json()
print(result)
```

## Langchain í†µí•©

### Langchain Toolë¡œ ì‚¬ìš©

```python
from langchain.tools import Tool
from scrapegraphai.graphs import SmartScraperGraph

def scrape_website(url: str) -> dict:
    """ì›¹ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜"""
    scraper = SmartScraperGraph(
        prompt="Extract main content",
        source=url,
        config={"llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}}
    )
    return scraper.run()

# Langchain Tool ìƒì„±
scraping_tool = Tool(
    name="WebScraper",
    func=scrape_website,
    description="Scrapes a website and extracts structured information"
)
```

### Agentì™€ í•¨ê»˜ ì‚¬ìš©

```python
from langchain.agents import initialize_agent, AgentType
from langchain_openai import ChatOpenAI

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", api_key="sk-...")

# Agent ìƒì„±
agent = initialize_agent(
    tools=[scraping_tool],
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# ì‹¤í–‰
response = agent.run("Scrape https://example.com and summarize the content")
print(response)
```

## LlamaIndex í†µí•©

### Readerë¡œ ì‚¬ìš©

```python
from llama_index.core import SimpleDirectoryReader
from scrapegraphai.graphs import SmartScraperGraph

class ScrapeGraphReader:
    def __init__(self, config):
        self.config = config

    def load_data(self, urls, prompt):
        """URLsì—ì„œ ë°ì´í„° ë¡œë“œ"""
        documents = []

        for url in urls:
            scraper = SmartScraperGraph(
                prompt=prompt,
                source=url,
                config=self.config
            )
            result = scraper.run()
            documents.append(result)

        return documents

# ì‚¬ìš©
reader = ScrapeGraphReader(
    config={"llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}}
)

docs = reader.load_data(
    urls=["https://site1.com", "https://site2.com"],
    prompt="Extract article content"
)
```

## CrewAI í†µí•©

### CrewAI Toolë¡œ ì‚¬ìš©

```python
from crewai import Agent, Task, Crew
from crewai_tools import tool
from scrapegraphai.graphs import SmartScraperGraph

@tool("Web Scraping Tool")
def scrape_tool(url: str, prompt: str) -> dict:
    """Scrapes a website using ScrapeGraphAI"""
    scraper = SmartScraperGraph(
        prompt=prompt,
        source=url,
        config={"llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}}
    )
    return scraper.run()

# Agent ìƒì„±
researcher = Agent(
    role="Research Analyst",
    goal="Gather competitive intelligence",
    tools=[scrape_tool],
    verbose=True
)

# Task ì •ì˜
task = Task(
    description="Scrape competitor websites and extract pricing info",
    agent=researcher
)

# Crew ì‹¤í–‰
crew = Crew(agents=[researcher], tasks=[task])
result = crew.kickoff()
```

## Agno í†µí•©

```python
from agno import Agent
from scrapegraphai.graphs import SmartScraperGraph

def scrape_data(url: str) -> dict:
    scraper = SmartScraperGraph(
        prompt="Extract product data",
        source=url,
        config={"llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}}
    )
    return scraper.run()

# Agno Agent
agent = Agent(
    name="Data Collector",
    tools=[scrape_data],
    model="openai/gpt-4o-mini"
)

response = agent.run("Collect product information from https://example.com")
```

## n8n í†µí•©

### n8n ë…¸ë“œ ì‚¬ìš©

1. n8nì—ì„œ "HTTP Request" ë…¸ë“œ ì¶”ê°€
2. URL: `https://api.scrapegraphai.com/v1/smartscraper`
3. Method: POST
4. Headers:
   - `Authorization: Bearer sgai-...`
   - `Content-Type: application/json`
5. Body:
   ```json
   {
     "website_url": "https://example.com",
     "user_prompt": "Extract data"
   }
   ```

### ì›Œí¬í”Œë¡œìš° ì˜ˆì œ

```
[Trigger] â†’ [HTTP Request (ScrapeGraphAI)] â†’ [Process Data] â†’ [Save to Database]
```

## Zapier í†µí•©

### Zapier App

1. [Zapier](https://zapier.com/apps/scrapegraphai/integrations) ì ‘ì†
2. "Create Zap" í´ë¦­
3. Trigger ì„ íƒ (ì˜ˆ: Google Sheets ìƒˆ í–‰)
4. Action: ScrapeGraphAI - Scrape Website
5. ì„¤ì •:
   - API Key: `sgai-...`
   - Website URL: íŠ¸ë¦¬ê±°ì˜ URL ì»¬ëŸ¼
   - User Prompt: "Extract product info"

### ì‚¬ìš© ì‚¬ë¡€

- **ë¦¬ë“œ ìƒì„±**: Google Sheets â†’ ScrapeGraphAI â†’ CRM
- **ê°€ê²© ëª¨ë‹ˆí„°ë§**: Scheduler â†’ ScrapeGraphAI â†’ Slack
- **ì½˜í…ì¸  ìˆ˜ì§‘**: RSS Feed â†’ ScrapeGraphAI â†’ Notion

## Pipedream í†µí•©

```javascript
// Pipedream Step
export default defineComponent({
  async run({ steps, $ }) {
    const response = await require("@pipedream/platform").axios($, {
      method: "POST",
      url: "https://api.scrapegraphai.com/v1/smartscraper",
      headers: {
        Authorization: `Bearer ${this.scrapegraphai.$auth.api_key}`,
      },
      data: {
        website_url: "https://example.com",
        user_prompt: "Extract data"
      }
    });

    return response;
  }
});
```

## Bubble í†µí•©

### API Connector ì„¤ì •

1. Bubble ì•±ì—ì„œ Plugins â†’ API Connector
2. Add API:
   - Name: ScrapeGraphAI
   - Authentication: Private key in header
   - Key: Authorization
   - Value: Bearer sgai-...
3. Add Call:
   - Name: smartscraper
   - Type: POST
   - URL: `https://api.scrapegraphai.com/v1/smartscraper`
   - Body:
     ```json
     {
       "website_url": "<url>",
       "user_prompt": "<prompt>"
     }
     ```

## MCP Server (Claude Desktop)

### ì„¤ì¹˜

```bash
npx @smithery/cli install @ScrapeGraphAI/scrapegraph-mcp --client claude
```

### ì‚¬ìš©

Claude Desktopì—ì„œ ë°”ë¡œ ì‚¬ìš©:

```
User: Scrape https://example.com and extract product names

Claude: [Uses ScrapeGraph MCP Server]
```

## Dify í†µí•©

DifyëŠ” LLM ì•± ê°œë°œ í”Œë«í¼ì…ë‹ˆë‹¤.

### Tool ì¶”ê°€

1. Dify Studio â†’ Tools
2. Add Custom Tool
3. ì„¤ì •:
   - Name: ScrapeGraphAI
   - Method: POST
   - URL: `https://api.scrapegraphai.com/v1/smartscraper`
   - Headers: Authorization, Content-Type
   - Body: JSON schema

## ì‹¤ì „ í™œìš© ì‚¬ë¡€

### ì‚¬ë¡€ 1: ìë™ ë¦¬ë“œ ìƒì„± íŒŒì´í”„ë¼ì¸

```
Google Sheets (ê¸°ì—… ëª©ë¡)
    â†“
Zapier Trigger (ìƒˆ í–‰ ì¶”ê°€)
    â†“
ScrapeGraphAI (íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘)
    â†“
Airtable (ë¦¬ë“œ ì €ì¥)
    â†“
Slack (ì•Œë¦¼)
```

### ì‚¬ë¡€ 2: ê²½ìŸì‚¬ ëª¨ë‹ˆí„°ë§

```
n8n Schedule (ë§¤ì¼ ì˜¤ì „ 9ì‹œ)
    â†“
ScrapeGraphAI (ê²½ìŸì‚¬ ê°€ê²© ìŠ¤í¬ë˜í•‘)
    â†“
Supabase (ë°ì´í„° ì €ì¥)
    â†“
Grafana (ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸)
    â†“
Discord (ë³€ê²½ì‚¬í•­ ì•Œë¦¼)
```

### ì‚¬ë¡€ 3: ì½˜í…ì¸  ì§‘ê³„ ë´‡

```python
# CrewAI + ScrapeGraphAI
from crewai import Agent, Task, Crew

# Content Collector Agent
collector = Agent(
    role="Content Collector",
    goal="Collect tech news from top sources",
    tools=[scrape_tool]
)

# Content Summarizer Agent
summarizer = Agent(
    role="Content Summarizer",
    goal="Create concise summaries"
)

# Tasks
collect_task = Task(
    description="Scrape tech news from 10 sources",
    agent=collector
)

summarize_task = Task(
    description="Summarize collected articles",
    agent=summarizer
)

# Run
crew = Crew(
    agents=[collector, summarizer],
    tasks=[collect_task, summarize_task]
)

result = crew.kickoff()
```

## ë¹„ìš© ë° ì œí•œì‚¬í•­

### API ê°€ê²©

- **Free**: 100 í¬ë ˆë”§ (í…ŒìŠ¤íŠ¸ìš©)
- **Starter**: $29/ì›” (1,000 í¬ë ˆë”§)
- **Professional**: $99/ì›” (5,000 í¬ë ˆë”§)
- **Enterprise**: ì»¤ìŠ¤í…€ ê°€ê²©

### Rate Limits

- Free: 10 requests/min
- Starter: 30 requests/min
- Professional: 100 requests/min

## ë‹¤ìŒ ë‹¨ê³„

ë§ˆì§€ë§‰ ì±•í„°ì—ì„œëŠ” **ì‹¤ì „ í™œìš© ë° íŒ**ì„ ë‹¤ë£¹ë‹ˆë‹¤.

---

## ì‹œë¦¬ì¦ˆ ë„¤ë¹„ê²Œì´ì…˜

- **ì´ì „**: [(8) LLM ëª¨ë¸ ì—°ë™]({{ site.baseurl }}/scrapegraph-guide-08-llm-integration/)
- **í˜„ì¬**: (9) í†µí•© ë° í™•ì¥
- **ë‹¤ìŒ**: [(10) ì‹¤ì „ í™œìš© ë° íŒ]({{ site.baseurl }}/scrapegraph-guide-10-tips/)

[ğŸ“š ì „ì²´ ëª©ì°¨ë¡œ ëŒì•„ê°€ê¸°]({{ site.baseurl }}/scrapegraph-guide/)
