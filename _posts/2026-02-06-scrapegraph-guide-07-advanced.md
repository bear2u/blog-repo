---
layout: post
title: "ScrapeGraphAI ì™„ë²½ ê°€ì´ë“œ (7) - ê³ ê¸‰ ê·¸ë˜í”„"
date: 2026-02-06
permalink: /scrapegraph-guide-07-advanced/
author: ScrapeGraphAI Team
categories: [AI ë„êµ¬, ì›¹ ìŠ¤í¬ë˜í•‘]
tags: [ScrapeGraphAI, CodeGenerator, ScriptCreator, SpeechGraph, Advanced]
original_url: "https://github.com/ScrapeGraphAI/Scrapegraph-ai"
excerpt: "ì½”ë“œ ìƒì„±, ìŠ¤í¬ë¦½íŠ¸ ìƒì„±, ìŒì„± ë³€í™˜ ë“± ê³ ê¸‰ ê¸°ëŠ¥ì„ íƒêµ¬í•©ë‹ˆë‹¤."
---

## ê³ ê¸‰ ê·¸ë˜í”„ ì†Œê°œ

ScrapeGraphAIëŠ” ë‹¨ìˆœ ìŠ¤í¬ë˜í•‘ì„ ë„˜ì–´ **ì½”ë“œ ìë™ ìƒì„±**, **ìŠ¤í¬ë¦½íŠ¸ ìƒì„±**, **ìŒì„± ë³€í™˜** ë“±ì˜ ê³ ê¸‰ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ScriptCreatorGraph

ì›¹í˜ì´ì§€ë¥¼ ë¶„ì„í•˜ì—¬ **ìŠ¤í¬ë˜í•‘ Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±**í•©ë‹ˆë‹¤.

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from scrapegraphai.graphs import ScriptCreatorGraph

script_generator = ScriptCreatorGraph(
    prompt="Extract all product names and prices",
    source="https://example.com/products",
    config={
        "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}
    }
)

python_script = script_generator.run()
print(python_script)
```

### ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ

```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com/products"
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')

products = []
for item in soup.select('.product-item'):
    name = item.select_one('.product-name').text.strip()
    price = item.select_one('.product-price').text.strip()
    products.append({
        'name': name,
        'price': price
    })

print(products)
```

### ìŠ¤í¬ë¦½íŠ¸ ì €ì¥ ë° ì‹¤í–‰

```python
script = script_generator.run()

# íŒŒì¼ë¡œ ì €ì¥
with open("scraper.py", "w") as f:
    f.write(script)

# ë°”ë¡œ ì‹¤í–‰
exec(script)
```

### ë©€í‹° í˜ì´ì§€ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

```python
from scrapegraphai.graphs import ScriptCreatorMultiGraph

multi_script_gen = ScriptCreatorMultiGraph(
    prompt="Extract article titles and URLs",
    source=[
        "https://news1.com",
        "https://news2.com",
        "https://news3.com"
    ],
    config={
        "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}
    }
)

scripts = multi_script_gen.run()

# ê° ì‚¬ì´íŠ¸ë³„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ë¨
for i, script in enumerate(scripts):
    with open(f"scraper_{i+1}.py", "w") as f:
        f.write(script)
```

## CodeGeneratorGraph

**BeautifulSoup, Selenium, Playwright ë“± ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬**ë¥¼ ì‚¬ìš©í•˜ëŠ” ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

### ì‚¬ìš© ì˜ˆì œ

```python
from scrapegraphai.graphs import CodeGeneratorGraph

code_gen = CodeGeneratorGraph(
    prompt="""
    Generate a Python script that:
    1. Uses Selenium to navigate to a login page
    2. Fills in username and password
    3. Clicks the login button
    4. Extracts user profile information
    5. Saves to JSON file
    """,
    source="https://example.com/login",
    config={
        "llm": {"model": "openai/gpt-4o", "api_key": "sk-..."}
    }
)

selenium_script = code_gen.run()
```

### ìƒì„±ëœ ì½”ë“œ (Selenium)

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import json

# ë“œë¼ì´ë²„ ì´ˆê¸°í™”
driver = webdriver.Chrome()

try:
    # ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì†
    driver.get("https://example.com/login")

    # ë¡œê·¸ì¸ ì •ë³´ ì…ë ¥
    username_field = driver.find_element(By.ID, "username")
    password_field = driver.find_element(By.ID, "password")

    username_field.send_keys("your_username")
    password_field.send_keys("your_password")

    # ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­
    login_button = driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
    login_button.click()

    # í”„ë¡œí•„ í˜ì´ì§€ ëŒ€ê¸°
    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, "profile"))
    )

    # í”„ë¡œí•„ ì •ë³´ ì¶”ì¶œ
    profile_data = {
        "name": driver.find_element(By.CLASS_NAME, "user-name").text,
        "email": driver.find_element(By.CLASS_NAME, "user-email").text,
    }

    # JSON ì €ì¥
    with open("profile.json", "w") as f:
        json.dump(profile_data, f, indent=2)

finally:
    driver.quit()
```

## SpeechGraph

ìŠ¤í¬ë˜í•‘í•œ ì½˜í…ì¸ ë¥¼ **ìŒì„± íŒŒì¼(MP3)**ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from scrapegraphai.graphs import SpeechGraph

speech_gen = SpeechGraph(
    prompt="Summarize this article in 2-3 sentences",
    source="https://blog.example.com/article",
    config={
        "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."},
        "tts_model": {
            "provider": "openai",
            "model": "tts-1",
            "voice": "alloy"
        }
    }
)

result = speech_gen.run()
```

### ê²°ê³¼ êµ¬ì¡°

```python
{
    "summary": "This article discusses...",
    "audio_file": "/tmp/speech_output.mp3"
}
```

### ìŒì„± ì˜µì…˜ ì„¤ì •

```python
config = {
    "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."},
    "tts_model": {
        "provider": "openai",
        "model": "tts-1-hd",  # ê³ í’ˆì§ˆ ìŒì„±
        "voice": "nova",       # alloy, echo, fable, onyx, nova, shimmer
        "speed": 1.0           # ì†ë„ (0.25 ~ 4.0)
    },
    "output_path": "./audio/summary.mp3"
}
```

### ì‹¤ìš© ì‚¬ë¡€: ë‰´ìŠ¤ íŒŸìºìŠ¤íŠ¸

```python
from scrapegraphai.graphs import SpeechGraph

news_urls = [
    "https://news.com/tech-news-1",
    "https://news.com/tech-news-2",
    "https://news.com/tech-news-3"
]

for i, url in enumerate(news_urls):
    speech_gen = SpeechGraph(
        prompt="Create a 30-second news summary",
        source=url,
        config={
            "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."},
            "tts_model": {
                "provider": "openai",
                "model": "tts-1",
                "voice": "alloy"
            },
            "output_path": f"./podcast/news_{i+1}.mp3"
        }
    )
    result = speech_gen.run()
    print(f"Generated: news_{i+1}.mp3")
```

## ScreenshotScraperGraph

ì›¹í˜ì´ì§€ì˜ **ìŠ¤í¬ë¦°ìƒ·ì„ ìº¡ì²˜**í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.

### ê¸°ë³¸ ì‚¬ìš©

```python
from scrapegraphai.graphs import ScreenshotScraperGraph

screenshot_scraper = ScreenshotScraperGraph(
    prompt="Describe the layout and main elements of this page",
    source="https://example.com",
    config={
        "llm": {"model": "openai/gpt-4o", "api_key": "sk-..."},
        "screenshot_path": "./screenshots/example.png"
    }
)

analysis = screenshot_scraper.run()
```

### Vision ëª¨ë¸ í™œìš©

```python
config = {
    "llm": {
        "model": "openai/gpt-4o",  # Vision ì§€ì› ëª¨ë¸
        "api_key": "sk-..."
    },
    "screenshot_options": {
        "full_page": True,        # ì „ì²´ í˜ì´ì§€ ìº¡ì²˜
        "width": 1920,
        "height": 1080
    }
}
```

## ì»¤ìŠ¤í…€ ê·¸ë˜í”„ ìƒì„±

ì§ì ‘ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ì–´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ê¸°ë³¸ êµ¬ì¡°

```python
from scrapegraphai.graphs import BaseGraph
from scrapegraphai.nodes import FetchNode, ParseNode, RAGNode

class CustomNewsGraph(BaseGraph):
    def __init__(self, prompt, source, config):
        super().__init__(prompt, source, config)

    def _create_graph(self):
        """ê·¸ë˜í”„ êµ¬ì¡° ì •ì˜"""
        # ë…¸ë“œ ìƒì„±
        fetch_node = FetchNode(
            "fetch",
            input="url",
            output=["html"],
            config=self.config
        )

        parse_node = ParseNode(
            "parse",
            input="html",
            output=["cleaned_html"],
            config=self.config
        )

        rag_node = RAGNode(
            "rag",
            input="cleaned_html | prompt",
            output=["answer"],
            config=self.config
        )

        # ë…¸ë“œ ì—°ê²°
        return [fetch_node, parse_node, rag_node]
```

### ì‚¬ìš©

```python
custom_scraper = CustomNewsGraph(
    prompt="Extract news headlines",
    source="https://news.example.com",
    config={"llm": {"model": "ollama/llama3.2"}}
)

result = custom_scraper.run()
```

## ì‹¤ì „ í™œìš© ì‚¬ë¡€

### ì‚¬ë¡€ 1: ìë™í™”ëœ ìŠ¤í¬ë˜í¼ ìƒì„±

```python
from scrapegraphai.graphs import ScriptCreatorGraph

# ê³ ê°ì‚¬ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ í›„ ë§ì¶¤ ìŠ¤í¬ë˜í¼ ìƒì„±
websites = [
    "https://client1.com/products",
    "https://client2.com/catalog",
    "https://client3.com/items"
]

for i, site in enumerate(websites):
    script_gen = ScriptCreatorGraph(
        prompt="Extract product name, price, and stock status",
        source=site,
        config={
            "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}
        }
    )

    script = script_gen.run()

    # ê³ ê°ë³„ ìŠ¤í¬ë˜í¼ ì œê³µ
    with open(f"client_{i+1}_scraper.py", "w") as f:
        f.write(script)
```

### ì‚¬ë¡€ 2: ì˜¤ë””ì˜¤ ë‰´ìŠ¤ ë¸Œë¦¬í•‘

```python
from scrapegraphai.graphs import SearchGraph, SpeechGraph

# 1ë‹¨ê³„: ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìš”ì•½
search_scraper = SearchGraph(
    prompt="What are the top 3 tech news today?",
    config={
        "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."},
        "max_results": 5
    }
)

news_summary = search_scraper.run()

# 2ë‹¨ê³„: ìŒì„±ìœ¼ë¡œ ë³€í™˜
speech_gen = SpeechGraph(
    prompt="Create a 2-minute audio briefing",
    source=news_summary,
    config={
        "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."},
        "tts_model": {
            "provider": "openai",
            "model": "tts-1",
            "voice": "nova"
        },
        "output_path": "./daily_briefing.mp3"
    }
)

audio_briefing = speech_gen.run()
print(f"Audio saved to: {audio_briefing['audio_file']}")
```

### ì‚¬ë¡€ 3: ê²½ìŸì‚¬ ëª¨ë‹ˆí„°ë§ ìë™í™”

```python
from scrapegraphai.graphs import ScriptCreatorMultiGraph
import schedule
import time

# ê²½ìŸì‚¬ ì›¹ì‚¬ì´íŠ¸ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
competitors = [
    "https://competitor1.com/pricing",
    "https://competitor2.com/features",
    "https://competitor3.com/updates"
]

script_gen = ScriptCreatorMultiGraph(
    prompt="Extract pricing, new features, and recent updates",
    source=competitors,
    config={
        "llm": {"model": "openai/gpt-4o-mini", "api_key": "sk-..."}
    }
)

monitoring_scripts = script_gen.run()

# ìƒì„±ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì •ê¸° ì‹¤í–‰
def run_monitoring():
    for i, script in enumerate(monitoring_scripts):
        exec(script)

# ë§¤ì¼ ì˜¤ì „ 9ì‹œ ì‹¤í–‰
schedule.every().day.at("09:00").do(run_monitoring)

while True:
    schedule.run_pending()
    time.sleep(60)
```

## ì„±ëŠ¥ ë° ë¹„ìš© ê³ ë ¤ì‚¬í•­

### Vision ëª¨ë¸ ë¹„ìš©

```python
# ìŠ¤í¬ë¦°ìƒ· ë¶„ì„ì€ Vision ëª¨ë¸ í•„ìš” (ë¹„ìš© ë†’ìŒ)
config = {
    "llm": {
        "model": "openai/gpt-4o",  # $2.50 / 1M tokens (input)
        "api_key": "sk-..."
    }
}

# í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ë¶„ì„ (ë¹„ìš© ì ˆê°)
config = {
    "llm": {
        "model": "openai/gpt-4o-mini",  # $0.15 / 1M tokens
        "api_key": "sk-..."
    }
}
```

### TTS ë¹„ìš©

```python
# OpenAI TTS ê°€ê²©: $15 / 1M characters
# ëŒ€ì•ˆ: ë¡œì»¬ TTS ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë¬´ë£Œ)
```

## ë‹¤ìŒ ë‹¨ê³„

ë‹¤ìŒ ì±•í„°ì—ì„œëŠ” **LLM ëª¨ë¸ ì—°ë™**ì„ ì‹¬ì¸µì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.

---

## ì‹œë¦¬ì¦ˆ ë„¤ë¹„ê²Œì´ì…˜

- **ì´ì „**: [(6) ë‹¤ì–‘í•œ ë°ì´í„° í¬ë§·]({{ site.baseurl }}/scrapegraph-guide-06-formats/)
- **í˜„ì¬**: (7) ê³ ê¸‰ ê·¸ë˜í”„
- **ë‹¤ìŒ**: [(8) LLM ëª¨ë¸ ì—°ë™]({{ site.baseurl }}/scrapegraph-guide-08-llm-integration/)

[ğŸ“š ì „ì²´ ëª©ì°¨ë¡œ ëŒì•„ê°€ê¸°]({{ site.baseurl }}/scrapegraph-guide/)
