---
layout: post
title: "ACE-Step 1.5 ì™„ë²½ ê°€ì´ë“œ (08) - LoRA í›ˆë ¨"
date: 2026-02-08
permalink: /ace-step-guide-08-lora-training/
author: ACE Studio & StepFun
categories: [AI ìŒì•…, ì˜¤í”ˆì†ŒìŠ¤]
tags: [ACE-Step, AI Music, LoRA, Fine-tuning, PEFT, Model Training]
original_url: "https://github.com/ace-step/ACE-Step-1.5"
excerpt: "8ê³¡, 1ì‹œê°„ìœ¼ë¡œ ë‚˜ë§Œì˜ ìŒì•… ìŠ¤íƒ€ì¼ ëª¨ë¸ ë§Œë“¤ê¸° - LoRA í›ˆë ¨ ì™„ë²½ ê°€ì´ë“œ"
---

## ê°œìš”

**LoRA (Low-Rank Adaptation)**ëŠ” ëŒ€ê·œëª¨ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ACE-Step 1.5ì—ì„œëŠ” ë‹¨ **8ê³¡ì˜ ë°ì´í„°**ì™€ **RTX 3090 ê¸°ì¤€ 1ì‹œê°„**ì˜ í›ˆë ¨ìœ¼ë¡œ ë‚˜ë§Œì˜ ìŒì•… ìŠ¤íƒ€ì¼ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## LoRAë€?

### ê°œë…

**LoRA (Low-Rank Adaptation of Large Language Models)**:
- ì›ë³¸ ëª¨ë¸ ê°€ì¤‘ì¹˜ëŠ” ê³ ì •(freeze)
- ì‘ì€ í¬ê¸°ì˜ ì–´ëŒ‘í„°(adapter) í–‰ë ¬ë§Œ í•™ìŠµ
- íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  ë¯¸ì„¸ ì¡°ì • (PEFT: Parameter-Efficient Fine-Tuning)

### ì‘ë™ ì›ë¦¬

```
ì›ë³¸ ê°€ì¤‘ì¹˜ (W)              LoRA ì–´ëŒ‘í„°
    â†“                          â†“
  ê³ ì •ë¨              A (rank Ã— input_dim)
                    Ã— B (output_dim Ã— rank)
                          â†“
                    Î”W = B Ã— A
                          â†“
              ìµœì¢… ê°€ì¤‘ì¹˜ = W + Î± Ã— Î”W
```

- `rank` (r): LoRAì˜ ìš©ëŸ‰, ë³´í†µ 64
- `alpha` (Î±): ìŠ¤ì¼€ì¼ë§ íŒ©í„°, ë³´í†µ 128 (2Ã—rank)
- **ì „ì²´ ëª¨ë¸ ëŒ€ë¹„ í›ˆë ¨ íŒŒë¼ë¯¸í„°: < 1%**

### ì¥ì 

| ì¥ì  | ì„¤ëª… |
|------|------|
| **íš¨ìœ¨ì„±** | ì „ì²´ ëª¨ë¸ ëŒ€ë¹„ 1% ë¯¸ë§Œ íŒŒë¼ë¯¸í„°ë§Œ í›ˆë ¨ |
| **ì†ë„** | RTX 3090ì—ì„œ 8ê³¡ ê¸°ì¤€ 1ì‹œê°„ |
| **ì €ë©”ëª¨ë¦¬** | 12GB VRAMìœ¼ë¡œ ì¶©ë¶„ (vs í’€ íŒŒì¸íŠœë‹ 80GB+) |
| **ëª¨ë“ˆì„±** | ì—¬ëŸ¬ LoRA ì–´ëŒ‘í„° êµì²´í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥ |
| **ì•ˆì •ì„±** | ì›ë³¸ ëª¨ë¸ ë³´ì¡´, ì–¸ì œë“  ë˜ëŒë¦´ ìˆ˜ ìˆìŒ |

### í™œìš© ì‚¬ë¡€

- **íŠ¹ì • ì¥ë¥´ íŠ¹í™”**: ì¬ì¦ˆ, K-pop, ë¡œíŒŒì´ ë“±
- **ì•„í‹°ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼**: íŠ¹ì • ì•„í‹°ìŠ¤íŠ¸ ìŒì•… ìŠ¤íƒ€ì¼ í•™ìŠµ
- **ìŒìƒ‰ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: íŠ¹ì • ë³´ì»¬/ì•…ê¸° ìŒìƒ‰ ê°•í™”
- **í…Œë§ˆ íŠ¹í™”**: í¬ë¦¬ìŠ¤ë§ˆìŠ¤, ë‰´ì´ì–´, ê²Œì„ OST ë“±

---

## Gradio UIì˜ LoRA Training íƒ­

ACE-Step 1.5ëŠ” **ì›í´ë¦­ LoRA í›ˆë ¨**ì„ ì§€ì›í•©ë‹ˆë‹¤.

### ì „ì²´ ì›Œí¬í”Œë¡œìš°

```
1. Dataset Builder â†’ ë°ì´í„°ì…‹ ì¤€ë¹„
   â”œâ”€ ì˜¤ë””ì˜¤ í´ë” ìŠ¤ìº”
   â”œâ”€ ìë™ ë¼ë²¨ë§ (Caption, Lyrics, BPM, Key)
   â””â”€ ë°ì´í„°ì…‹ JSON ì €ì¥

2. Preprocess â†’ ì „ì²˜ë¦¬
   â”œâ”€ VAE latent ì¸ì½”ë”©
   â”œâ”€ Text embedding ìƒì„±
   â””â”€ Tensor íŒŒì¼ ì €ì¥

3. Train LoRA â†’ í›ˆë ¨
   â”œâ”€ LoRA íŒŒë¼ë¯¸í„° ì„¤ì •
   â”œâ”€ í›ˆë ¨ ì‹¤í–‰
   â””â”€ ì²´í¬í¬ì¸íŠ¸ ì €ì¥

4. Export â†’ LoRA ì–´ëŒ‘í„° ë‚´ë³´ë‚´ê¸°
```

---

## ë°ì´í„°ì…‹ ì¤€ë¹„

### ê¶Œì¥ ì‚¬í•­

| í•­ëª© | ê¶Œì¥ ê°’ | ìµœì†Œ | ìµœì  |
|------|---------|------|------|
| **ê³¡ ìˆ˜** | 8+ | 5 | 20+ |
| **ì´ ê¸¸ì´** | 30ë¶„+ | 15ë¶„ | 60ë¶„+ |
| **ì˜¤ë””ì˜¤ í˜•ì‹** | WAV, MP3, FLAC | - | WAV (ë¬´ì†ì‹¤) |
| **ìƒ˜í”Œë ˆì´íŠ¸** | 48kHz | 44.1kHz | 48kHz |
| **ë¹„íŠ¸ ëìŠ¤** | 16-bit | 16-bit | 24-bit |
| **ê¸¸ì´ ë¶„í¬** | 2-5ë¶„/ê³¡ | - | ë‹¤ì–‘í•œ ê¸¸ì´ |
| **ìŠ¤íƒ€ì¼ ì¼ê´€ì„±** | ë†’ìŒ | - | ë‹¨ì¼ ìŠ¤íƒ€ì¼ |

### ë°ì´í„° í’ˆì§ˆ íŒ

**ì¢‹ì€ ë°ì´í„°**:
- ëª…í™•í•œ ìŠ¤íƒ€ì¼ ì •ì²´ì„±
- ê³ í’ˆì§ˆ í”„ë¡œë•ì…˜
- ì¼ê´€ëœ ìŒìƒ‰/ë¯¹ì‹±
- ë‹¤ì–‘í•œ ê³¡ êµ¬ì¡°

**í”¼í•´ì•¼ í•  ê²ƒ**:
- ë¼ì´ë¸Œ ë…¹ìŒ (ê´€ì¤‘ ì†ŒìŒ)
- ì••ì¶• ì•„í‹°íŒ©íŠ¸ ì‹¬í•œ MP3
- ìŠ¤íƒ€ì¼ í˜¼ì¬ (ì¬ì¦ˆ + ë©”íƒˆ í˜¼í•©)
- ë„ˆë¬´ ì§§ì€ í´ë¦½ (< 1ë¶„)

---

## Dataset Builder íƒ­: ë‹¨ê³„ë³„ ê°€ì´ë“œ

### Step 1: ì˜¤ë””ì˜¤ ìŠ¤ìº”

**ìƒˆ ë°ì´í„°ì…‹ ì‹œì‘**:
```
Audio Folder Path: /path/to/your/music/folder
â†’ Scan ë²„íŠ¼ í´ë¦­
```

ì§€ì› í˜•ì‹: `.wav`, `.mp3`, `.flac`, `.ogg`, `.opus`

**ê¸°ì¡´ ë°ì´í„°ì…‹ ë¡œë“œ**:
```
Dataset JSON Path: /path/to/dataset.json
â†’ Load ë²„íŠ¼ í´ë¦­
```

### Step 2: ë°ì´í„°ì…‹ ì„¤ì •

| ì„¤ì • | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| **Dataset Name** | ë°ì´í„°ì…‹ ì´ë¦„ | "my-jazz-dataset" |
| **All Instrumental** | ëª¨ë“  íŠ¸ë™ì´ ì—°ì£¼ê³¡ì¸ ê²½ìš° ì²´í¬ | â˜ |
| **Custom Activation Tag** | LoRA í™œì„±í™” íƒœê·¸ (ê³ ìœ í•´ì•¼ í•¨) | "myjazz", "xmas2024" |
| **Tag Position** | íƒœê·¸ ìœ„ì¹˜ ì„ íƒ | Prepend / Append / Replace |

**Activation Tag ì„¤ëª…**:
- ìƒì„± ì‹œ Captionì— ì´ íƒœê·¸ë¥¼ í¬í•¨í•˜ë©´ LoRA ìŠ¤íƒ€ì¼ í™œì„±í™”
- ì˜ˆ: Captionì— "myjazz" í¬í•¨ â†’ ì¬ì¦ˆ ìŠ¤íƒ€ì¼ LoRA ì ìš©

**Tag Position**:
- **Prepend**: Caption ì•ì— ì¶”ê°€ (`"myjazz, piano ballad"`)
- **Append**: Caption ë’¤ì— ì¶”ê°€ (`"piano ballad, myjazz"`)
- **Replace**: Caption ì „ì²´ë¥¼ íƒœê·¸ë¡œ ëŒ€ì²´ (`"myjazz"`)

### Step 3: ìë™ ë¼ë²¨ë§

```
Auto-Label All ë²„íŠ¼ í´ë¦­
```

**ìë™ ìƒì„±ë˜ëŠ” í•­ëª©**:
- **Caption**: ìŒì•… ìŠ¤íƒ€ì¼, ì•…ê¸°, ë¶„ìœ„ê¸° ì„¤ëª…
- **BPM**: í…œí¬ ì¶”ë¡ 
- **Key**: ì¡°ì„± ì¶”ë¡  (C Major, Am ë“±)
- **Time Signature**: ë°•ì ì¶”ë¡  (4/4, 3/4 ë“±)

**Skip Metas ì˜µì…˜**:
- ì²´í¬ ì‹œ LLM ë¼ë²¨ë§ ê±´ë„ˆë›°ê³  N/A ê°’ ì‚¬ìš©
- ë©”íƒ€ë°ì´í„° ë¶ˆí•„ìš”í•œ ê²½ìš° ì‹œê°„ ì ˆì•½

### Step 4: ìˆ˜ë™ í¸ì§‘ (ì„ íƒì‚¬í•­)

ìŠ¬ë¼ì´ë”ë¡œ ìƒ˜í”Œ ì„ íƒ í›„ ìˆ˜ë™ í¸ì§‘:

```
Caption: [ìë™ ìƒì„±ëœ caption ìˆ˜ì • ê°€ëŠ¥]
Lyrics: [ê°€ì‚¬ ì…ë ¥ ë˜ëŠ” ìˆ˜ì •]
BPM: [í…œí¬ ì¡°ì •]
Key: [ì¡°ì„± ì„ íƒ]
Time Signature: [ë°•ì ì„ íƒ]
Language: [ë³´ì»¬ ì–¸ì–´]
Instrumental: [ì—°ì£¼ê³¡ ì—¬ë¶€]

â†’ Save Changes í´ë¦­
```

**í¸ì§‘ íŒ**:
- Caption êµ¬ì²´í™”: "jazz" â†’ "smooth jazz with saxophone and piano"
- Lyrics ì¶”ê°€: ìë™ ì¶”ì¶œë˜ì§€ ì•Šì€ ê°€ì‚¬ ìˆ˜ë™ ì…ë ¥
- ë©”íƒ€ë°ì´í„° ì •í™•ë„ ê²€ì¦

### Step 5: ë°ì´í„°ì…‹ ì €ì¥

```
Save Path: /path/to/save/dataset.json
â†’ Save Dataset ë²„íŠ¼ í´ë¦­
```

**ì €ì¥ë˜ëŠ” ë‚´ìš©**:
```json
{
  "dataset_name": "my-jazz-dataset",
  "activation_tag": "myjazz",
  "tag_position": "prepend",
  "samples": [
    {
      "audio_path": "/path/to/song1.wav",
      "caption": "myjazz, smooth jazz with saxophone",
      "lyrics": "[Instrumental]",
      "bpm": 90,
      "keyscale": "Bb Major",
      "timesignature": 4,
      "language": "unknown",
      "instrumental": true
    },
    ...
  ]
}
```

---

## Preprocess: ì „ì²˜ë¦¬

### ëª©ì 

í›ˆë ¨ ì†ë„ í–¥ìƒì„ ìœ„í•´ ì‚¬ì „ ê³„ì‚°:
1. **VAE Latents**: ì˜¤ë””ì˜¤ â†’ ì ì¬ í‘œí˜„ ì¸ì½”ë”©
2. **Text Embeddings**: Caption/Lyrics â†’ ì„ë² ë”©
3. **Condition Encoder**: ì¡°ê±´ ì¸ì½”ë” ì‹¤í–‰

### ì‚¬ìš© ë°©ë²•

```
Dataset JSON Path: /path/to/dataset.json
Preprocessed Tensors Output Directory: /path/to/tensors/
â†’ Preprocess ë²„íŠ¼ í´ë¦­
```

### ì²˜ë¦¬ ì‹œê°„

| GPU | 8ê³¡ (30ë¶„) ì „ì²˜ë¦¬ ì‹œê°„ |
|-----|----------------------|
| RTX 3090 | ~5-10ë¶„ |
| RTX 4090 | ~3-5ë¶„ |
| A100 | ~2-3ë¶„ |

### ì¶œë ¥ êµ¬ì¡°

```
/path/to/tensors/
â”œâ”€â”€ sample_0.pt
â”œâ”€â”€ sample_1.pt
â”œâ”€â”€ sample_2.pt
...
â””â”€â”€ sample_7.pt
```

ê° `.pt` íŒŒì¼ í¬í•¨ ë‚´ìš©:
```python
{
    "target_latents": tensor,      # VAE ì¸ì½”ë”© ì˜¤ë””ì˜¤
    "encoder_hidden_states": tensor,  # Text embedding
    "context_latents": tensor,     # ì¡°ê±´ ì»¨í…ìŠ¤íŠ¸
    "metadata": {...}              # BPM, Key ë“±
}
```

---

## Train LoRA íƒ­: í›ˆë ¨ ì‹¤í–‰

### Step 1: ë°ì´í„°ì…‹ ë¡œë“œ

```
Preprocessed Tensors Directory: /path/to/tensors/
â†’ Load Dataset ë²„íŠ¼ í´ë¦­
```

### Step 2: LoRA ì„¤ì •

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ë²”ìœ„ | ì„¤ëª… |
|----------|--------|------|------|
| **LoRA Rank (r)** | 64 | 8-256 | LoRA ìš©ëŸ‰. ë†’ì„ìˆ˜ë¡ í‘œí˜„ë ¥ ì¦ê°€, ë©”ëª¨ë¦¬ ì¦ê°€ |
| **LoRA Alpha** | 128 | r-4r | ìŠ¤ì¼€ì¼ë§ íŒ©í„°. ë³´í†µ 2Ã—rank |
| **LoRA Dropout** | 0.1 | 0.0-0.5 | ê³¼ì í•© ë°©ì§€. 0.1 ê¶Œì¥ |

**Rank ì„ íƒ ê°€ì´ë“œ**:
- **rank=32**: ë¯¸ì„¸í•œ ìŠ¤íƒ€ì¼ ì¡°ì •, ë¹ ë¥¸ í›ˆë ¨
- **rank=64**: ê· í˜•ì¡íŒ ì„ íƒ (ê¶Œì¥)
- **rank=128**: ë³µì¡í•œ ìŠ¤íƒ€ì¼, ë” ë§ì€ ë©”ëª¨ë¦¬

### Step 3: í›ˆë ¨ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ë²”ìœ„ | ì„¤ëª… |
|----------|--------|------|------|
| **Learning Rate** | 1e-4 | 1e-5 ~ 1e-3 | í•™ìŠµë¥ . ë„ˆë¬´ ë†’ìœ¼ë©´ ë¶ˆì•ˆì • |
| **Max Epochs** | 500 | 100-2000 | ìµœëŒ€ ì—í¬í¬. 8ê³¡ ê¸°ì¤€ 500 ì ì ˆ |
| **Batch Size** | 1 | 1-4 | ë°°ì¹˜ í¬ê¸°. GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì • |
| **Gradient Accumulation** | 1 | 1-8 | ìœ íš¨ ë°°ì¹˜ = batch_size Ã— accumulation |
| **Save Every N Epochs** | 200 | 50-500 | ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì£¼ê¸° |
| **Shift** | 3.0 | 1.0-5.0 | Turbo ëª¨ë¸ìš© íƒ€ì„ìŠ¤í… ì‹œí”„íŠ¸ |
| **Seed** | 42 | - | ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ |

### Step 4: í›ˆë ¨ ì‹œì‘

```
â†’ Start Training ë²„íŠ¼ í´ë¦­
```

**í›ˆë ¨ ì¤‘ ëª¨ë‹ˆí„°ë§**:
- **Training Progress**: í˜„ì¬ ì—í¬í¬ ë° ì†ì‹¤ í‘œì‹œ
- **Training Log**: ìƒì„¸ ë¡œê·¸ ì¶œë ¥
- **Training Loss Plot**: ì†ì‹¤ ê·¸ë˜í”„ ì‹œê°í™”

**ì˜ˆìƒ í›ˆë ¨ ì‹œê°„**:

| GPU | 8ê³¡, 500 ì—í¬í¬ |
|-----|----------------|
| RTX 3090 (24GB) | ~1ì‹œê°„ |
| RTX 4090 (24GB) | ~40ë¶„ |
| A100 (40GB) | ~30ë¶„ |

### Step 5: í›ˆë ¨ ì¤‘ë‹¨ (ì„ íƒì‚¬í•­)

```
â†’ Stop Training ë²„íŠ¼ í´ë¦­
```

ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ê°€ ì €ì¥ë©ë‹ˆë‹¤.

### Step 6: LoRA ë‚´ë³´ë‚´ê¸°

```
Export Path: /path/to/save/my_lora/
â†’ Export LoRA ë²„íŠ¼ í´ë¦­
```

**ë‚´ë³´ë‚´ì§„ íŒŒì¼**:
```
/path/to/save/my_lora/
â”œâ”€â”€ adapter_config.json   # LoRA ì„¤ì •
â””â”€â”€ adapter_model.bin     # LoRA ê°€ì¤‘ì¹˜
```

---

## LoRA ëª¨ë¸ ì‚¬ìš© ë°©ë²•

### 1. Gradio UIì—ì„œ ì‚¬ìš©

**Service Configuration íƒ­**:
```
LoRA Path: /path/to/my_lora/
â†’ Load LoRA ë²„íŠ¼ í´ë¦­
â†’ Use LoRA ì²´í¬ë°•ìŠ¤ í™œì„±í™”
```

**ìƒì„± ì‹œ**:
```
Caption: "myjazz, smooth piano and saxophone duet"
# â†’ LoRA ìŠ¤íƒ€ì¼ ìë™ ì ìš©
```

### 2. Python APIì—ì„œ ì‚¬ìš©

```python
from acestep import AceStepPipeline

# LoRA ë¡œë“œ
pipeline = AceStepPipeline(
    model_path="acestep-v15-turbo",
    lora_path="/path/to/my_lora/"
)

# ìƒì„±
result = pipeline.generate(
    caption="myjazz, late night jazz cafe atmosphere",
    lyrics="[Instrumental]"
)
```

### 3. LoRA í™œì„±í™”/ë¹„í™œì„±í™”

```python
# LoRA í™œì„±í™”
pipeline.enable_lora()

# LoRA ë¹„í™œì„±í™” (ì›ë³¸ ëª¨ë¸ ì‚¬ìš©)
pipeline.disable_lora()

# LoRA ì–¸ë¡œë“œ
pipeline.unload_lora()
```

### 4. ì—¬ëŸ¬ LoRA êµì²´ ì‚¬ìš©

```python
# ì¬ì¦ˆ LoRA
pipeline.load_lora("/path/to/jazz_lora/")
jazz_song = pipeline.generate(caption="myjazz, piano trio")

# ë¡œíŒŒì´ LoRAë¡œ êµì²´
pipeline.unload_lora()
pipeline.load_lora("/path/to/lofi_lora/")
lofi_song = pipeline.generate(caption="mylofi, chill beats")
```

---

## í›ˆë ¨ íŒŒë¼ë¯¸í„° ìµœì í™”

### Learning Rate ì¡°ì •

**ì¦ìƒë³„ ì¡°ì •**:

| ì¦ìƒ | ì›ì¸ | í•´ê²°ì±… |
|------|------|--------|
| Lossê°€ ë–¨ì–´ì§€ì§€ ì•ŠìŒ | LR ë„ˆë¬´ ë‚®ìŒ | LR ì¦ê°€ (1e-4 â†’ 3e-4) |
| Lossê°€ í­ë°œí•¨ (NaN) | LR ë„ˆë¬´ ë†’ìŒ | LR ê°ì†Œ (1e-4 â†’ 5e-5) |
| Lossê°€ ì§„ë™í•¨ | LR ë¶ˆì•ˆì • | LR ê°ì†Œ + Warmup ì‚¬ìš© |

### Epoch ìˆ˜ ì¡°ì •

**ë°ì´í„°ì…‹ í¬ê¸°ë³„**:

| ë°ì´í„°ì…‹ | ê¶Œì¥ Epochs | ì´ìœ  |
|----------|-------------|------|
| 5ê³¡ ë¯¸ë§Œ | 800-1000 | ë” ë§ì€ ë°˜ë³µ í•„ìš” |
| 8-15ê³¡ | 500-800 | ê· í˜• (ê¶Œì¥) |
| 20ê³¡ ì´ìƒ | 300-500 | ê³¼ì í•© ìœ„í—˜ ê°ì†Œ |

**Early Stopping íŒë‹¨**:
- Lossê°€ ë” ì´ìƒ ê°ì†Œí•˜ì§€ ì•ŠìŒ
- ìƒì„± ê²°ê³¼ê°€ í›ˆë ¨ ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì œ (ê³¼ì í•©)
- Validation loss ì¦ê°€ ì‹œì‘

### Batch Size & Gradient Accumulation

**ë©”ëª¨ë¦¬ ì œì•½ ì‹œ**:

| VRAM | Batch Size | Accumulation | ìœ íš¨ Batch |
|------|-----------|--------------|-----------|
| 12GB | 1 | 4 | 4 |
| 16GB | 1 | 8 | 8 |
| 24GB | 2 | 4 | 8 |
| 40GB+ | 4 | 4 | 16 |

```python
# ì˜ˆ: 12GB GPU
batch_size = 1
gradient_accumulation = 4
# â†’ ìœ íš¨ ë°°ì¹˜ í¬ê¸° = 4
```

### LoRA Rank ìµœì í™”

**ìŠ¤íƒ€ì¼ ë³µì¡ë„ë³„**:

| ìŠ¤íƒ€ì¼ ë³µì¡ë„ | Rank | ì˜ˆì‹œ |
|--------------|------|------|
| ë‹¨ìˆœ (ìŒìƒ‰ ì¡°ì •) | 32 | íŠ¹ì • ë³´ì»¬ ìŒìƒ‰ |
| ì¤‘ê°„ (ì¥ë¥´ ìŠ¤íƒ€ì¼) | 64 | ì¬ì¦ˆ, ë¡œíŒŒì´ |
| ë³µì¡ (ë‹¤ì¤‘ ìš”ì†Œ) | 128 | ì˜¤ì¼€ìŠ¤íŠ¸ë¼, í“¨ì „ |

---

## Fine-tuning ëª¨ë²” ì‚¬ë¡€

### 1. ë°ì´í„° íë ˆì´ì…˜

**DO**:
- ì¼ê´€ëœ ìŠ¤íƒ€ì¼ ì„ íƒ
- ê³ í’ˆì§ˆ í”„ë¡œë•ì…˜ë§Œ í¬í•¨
- ë‹¤ì–‘í•œ ê³¡ êµ¬ì¡° í¬í•¨
- ëª…í™•í•œ ìŠ¤íƒ€ì¼ ì •ì²´ì„±

**DON'T**:
- ì—¬ëŸ¬ ì¥ë¥´ í˜¼í•©
- ì €í’ˆì§ˆ ë…¹ìŒ í¬í•¨
- ëª¨ë“  ê³¡ì´ ë¹„ìŠ·í•œ êµ¬ì¡°
- ìŠ¤íƒ€ì¼ì´ ëª¨í˜¸í•œ ê³¡

### 2. Activation Tag ì „ëµ

**ì¢‹ì€ íƒœê·¸**:
- ì§§ê³  ê¸°ì–µí•˜ê¸° ì‰¬ì›€: `"myjazz"`, `"xmas24"`
- ê³ ìœ í•¨: ê¸°ì¡´ ë‹¨ì–´ì™€ ì¶©ëŒ ì—†ìŒ
- ì†Œë¬¸ì: `"myjazz"` (O), `"MyJazz"` (X)

**ë‚˜ìœ íƒœê·¸**:
- ì¼ë°˜ ë‹¨ì–´: `"jazz"` (ëª¨ë¸ì´ ì´ë¯¸ ì•Œê³  ìˆìŒ)
- ë„ˆë¬´ ê¸¸ê±°ë‚˜ ë³µì¡: `"my-custom-jazz-style-2024"`
- íŠ¹ìˆ˜ë¬¸ì: `"my_jazz!"` (íŒŒì‹± ì˜¤ë¥˜ ê°€ëŠ¥)

### 3. í›ˆë ¨ ëª¨ë‹ˆí„°ë§

**Loss ì²´í¬í¬ì¸íŠ¸**:
```
Epoch 100: Loss 0.25  â† ì´ˆê¸°, ë¹ ë¥´ê²Œ ê°ì†Œ
Epoch 200: Loss 0.12  â† ì¤‘ê°„, ê°ì†Œ ì†ë„ ë‘”í™”
Epoch 300: Loss 0.08  â† ìˆ˜ë ´ ì‹œì‘
Epoch 400: Loss 0.06  â† ì•ˆì •ì 
Epoch 500: Loss 0.05  â† ì™„ë£Œ
```

**ê³¼ì í•© ì‹ í˜¸**:
- Lossê°€ 0ì— ë„ˆë¬´ ê°€ê¹Œì›€ (< 0.01)
- ìƒì„± ê²°ê³¼ê°€ í›ˆë ¨ ë°ì´í„°ì™€ ê±°ì˜ ë™ì¼
- ìƒˆë¡œìš´ Captionì— ëŒ€í•œ ì¼ë°˜í™” ì‹¤íŒ¨

### 4. í…ŒìŠ¤íŠ¸ ì „ëµ

**í›ˆë ¨ ì¤‘ í…ŒìŠ¤íŠ¸**:
```python
# 200 ì—í¬í¬ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
save_every_n_epochs = 200

# ê° ì²´í¬í¬ì¸íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ìƒì„±
for checkpoint in ["epoch_200", "epoch_400", "epoch_600"]:
    pipeline.load_lora(f"/path/to/{checkpoint}/")
    test = pipeline.generate(caption="myjazz, test prompt")
    save(test, f"test_{checkpoint}.mp3")
```

**ìµœì  ì²´í¬í¬ì¸íŠ¸ ì„ íƒ**:
1. ì—¬ëŸ¬ ì—í¬í¬ ì²´í¬í¬ì¸íŠ¸ ìƒì„±
2. ê° ì²´í¬í¬ì¸íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ìƒì„±
3. í’ˆì§ˆ + ì¼ë°˜í™” ëŠ¥ë ¥ ê· í˜• í‰ê°€
4. ìµœì  ì²´í¬í¬ì¸íŠ¸ ì„ íƒ

### 5. ë°ì´í„° ì¦ê°•

**ë¶€ì¡±í•œ ë°ì´í„° ë³´ì™„**:
```python
# ì›ë³¸ 8ê³¡ â†’ Repaintë¡œ ë³€í˜• ìƒì„± â†’ 16ê³¡

for song in original_8_songs:
    # ì¤‘ê°„ êµ¬ê°„ ì¬ìƒì„± (ë³€í˜•)
    variant = generate(
        task_type="repaint",
        src_audio=song,
        repainting_start=60,
        repainting_end=90,
        caption="slight variation in style"
    )
    augmented_dataset.append(variant)

# ì´ 16ê³¡ìœ¼ë¡œ í›ˆë ¨
```

---

## ì‹¤ì „ ì˜ˆì œ

### ì˜ˆì œ 1: í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ìºë¡¤ LoRA

**ë°ì´í„°ì…‹**:
- 20ê³¡ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ìºë¡¤
- ìŠ¤íƒ€ì¼: ì „í†µì , ì˜¤ì¼€ìŠ¤íŠ¸ë¼, í•©ì°½

**ì„¤ì •**:
```
Dataset Name: christmas-carols
Activation Tag: xmas
Tag Position: Prepend

LoRA Rank: 64
Learning Rate: 1e-4
Max Epochs: 400
```

**ì‚¬ìš©**:
```python
pipeline.load_lora("/path/to/xmas_lora/")

result = pipeline.generate(
    caption="xmas, traditional carol with choir and bells",
    lyrics="""
[Chorus]
Jingle bells, jingle bells
Jingle all the way
...
"""
)
```

### ì˜ˆì œ 2: K-pop ìŠ¤íƒ€ì¼ LoRA

**ë°ì´í„°ì…‹**:
- 15ê³¡ í˜„ëŒ€ K-pop
- íŠ¹ì§•: ê°•í•œ ë¹„íŠ¸, ì‹ ìŠ¤, ë‹¤ì´ë‚˜ë¯¹í•œ êµ¬ì¡°

**ì„¤ì •**:
```
Dataset Name: kpop-style
Activation Tag: mykpop
Tag Position: Prepend

LoRA Rank: 128  # ë³µì¡í•œ ìŠ¤íƒ€ì¼
Learning Rate: 8e-5
Max Epochs: 600
```

**ì‚¬ìš©**:
```python
result = pipeline.generate(
    caption="mykpop, energetic dance pop with heavy bass and synths",
    lyrics="""
[Intro - building]

[Verse 1]
ì‹œì‘ë˜ëŠ” ì´ ìˆœê°„
...

[Chorus - explosive]
WE ARE THE CHAMPIONS
...
"""
)
```

### ì˜ˆì œ 3: ë¡œíŒŒì´ ë¹„íŠ¸ LoRA

**ë°ì´í„°ì…‹**:
- 10ê³¡ ë¡œíŒŒì´ í™í•© ë¹„íŠ¸
- íŠ¹ì§•: í¬ë˜í´ ë…¸ì´ì¦ˆ, ì¬ì¦ˆ ìƒ˜í”Œ, ëŠë¦° í…œí¬

**ì„¤ì •**:
```
Dataset Name: lofi-beats
Activation Tag: mylofi
Tag Position: Prepend
All Instrumental: âœ“

LoRA Rank: 64
Learning Rate: 1e-4
Max Epochs: 500
```

**ì‚¬ìš©**:
```python
result = pipeline.generate(
    caption="mylofi, chill lofi beat with vinyl crackle and jazz samples",
    lyrics="[Instrumental]",
    bpm=85
)
```

---

## ë¬¸ì œ í•´ê²°

### í›ˆë ¨ ì¤‘ ë©”ëª¨ë¦¬ ë¶€ì¡±

**Windows / ë‚®ì€ VRAM ì‹œìŠ¤í…œ**:

**ì¦ìƒ**:
- ì „ì²˜ë¦¬ ì¤‘ ë©ˆì¶¤
- Epoch ì‚¬ì´ì— ê¸´ ì •ì§€
- Out of Memory ì˜¤ë¥˜

**í•´ê²°ì±…**:

1. **ë¯¸ì‚¬ìš© ëª¨ë¸ ì˜¤í”„ë¡œë“œ**:
```
Service Configuration:
  Offload to CPU: âœ“
  Offload DiT to CPU: âœ“
```

2. **íƒ€ì¼ ì¸ì½”ë”© ì‚¬ìš©**:
```python
# ì „ì²˜ë¦¬ ì‹œ íƒ€ì¼ ì¸ì½”ë”©ìœ¼ë¡œ í”¼í¬ ë©”ëª¨ë¦¬ ê°ì†Œ
use_tiled_encode = True
```

3. **ë°°ì¹˜ í¬ê¸° ê°ì†Œ**:
```
Batch Size: 1
Gradient Accumulation: 4  # ìœ íš¨ ë°°ì¹˜ ìœ ì§€
```

4. **Persistent Workers ê°œì„ **:
- ìµœì‹  ë²„ì „ì€ Windows epoch ê²½ê³„ ì •ì§€ ìë™ ê°œì„ 
- ì—¬ì „íˆ ë¬¸ì œ ì‹œ `num_workers=0` ì„¤ì •

### Lossê°€ NaNì´ ë¨

**ì›ì¸**: Learning rate ë„ˆë¬´ ë†’ìŒ

**í•´ê²°ì±…**:
```
Learning Rate: 1e-4 â†’ 5e-5
```

### ê³¼ì í•© (ìƒì„± ê²°ê³¼ê°€ í›ˆë ¨ ë°ì´í„° ë³µì œ)

**í•´ê²°ì±…**:
1. ë” ë§ì€ ë°ì´í„° ì¶”ê°€ (8ê³¡ â†’ 15ê³¡)
2. Dropout ì¦ê°€ (`0.1` â†’ `0.2`)
3. Epoch ê°ì†Œ (`500` â†’ `300`)
4. LoRA Rank ê°ì†Œ (`128` â†’ `64`)

### ìƒì„± ê²°ê³¼ê°€ ìŠ¤íƒ€ì¼ ë°˜ì˜ ì•ˆ ë¨

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
1. Activation tag í¬í•¨ í™•ì¸: Captionì— `"myjazz"` í¬í•¨?
2. LoRA ë¡œë“œ í™•ì¸: `Use LoRA` ì²´í¬ë°•ìŠ¤ í™œì„±í™”?
3. ì¶©ë¶„í•œ í›ˆë ¨: ìµœì†Œ 300+ epoch?
4. Captionê³¼ í›ˆë ¨ ë°ì´í„° ì¼ì¹˜: ìŠ¤íƒ€ì¼ ì„¤ëª…ì´ ë°ì´í„°ì™€ ì¼ì¹˜?

---

## ì„±ëŠ¥ ìµœì í™”

### GPUë³„ ìµœì  ì„¤ì •

**RTX 3090 (24GB)**:
```
Batch Size: 1
Gradient Accumulation: 4
LoRA Rank: 64
Offload to CPU: âœ—  (ì¶©ë¶„í•œ VRAM)
```

**RTX 4080 (16GB)**:
```
Batch Size: 1
Gradient Accumulation: 4
LoRA Rank: 64
Offload to CPU: âœ“  (ì•ˆì „)
```

**RTX 3060 (12GB)**:
```
Batch Size: 1
Gradient Accumulation: 2
LoRA Rank: 32
Offload to CPU: âœ“
Use Tiled Encode: âœ“
```

### í›ˆë ¨ ì†ë„ í–¥ìƒ

1. **ì „ì²˜ë¦¬ ìºì‹±**: ì „ì²˜ë¦¬ëŠ” í•œ ë²ˆë§Œ, ì—¬ëŸ¬ ë²ˆ ì¬ì‚¬ìš©
2. **ì²´í¬í¬ì¸íŠ¸ ì£¼ê¸° ì¡°ì •**: `Save Every N Epochs: 200 â†’ 500` (I/O ê°ì†Œ)
3. **Mixed Precision**: ìë™ í™œì„±í™” (bfloat16)

---

## ë‹¤ìŒ ë‹¨ê³„

LoRA í›ˆë ¨ì„ ë§ˆìŠ¤í„°í–ˆë‹¤ë©´:

1. **ì—¬ëŸ¬ LoRA ì¡°í•©**: ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ LoRA ë§Œë“¤ì–´ êµì²´ ì‚¬ìš©
2. **ë°ì´í„°ì…‹ í™•ì¥**: ë” ë§ì€ ê³¡ìœ¼ë¡œ í’ˆì§ˆ í–¥ìƒ
3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‹¤í—˜**: Rank, LR ë“± ìµœì ê°’ íƒìƒ‰
4. **ì»¤ë®¤ë‹ˆí‹° ê³µìœ **: í›Œë¥­í•œ LoRAëŠ” ì»¤ë®¤ë‹ˆí‹°ì™€ ê³µìœ 

---

## ì°¸ê³  ìë£Œ

- [ACE-Step 1.5 LoRA Training Code](https://github.com/ace-step/ACE-Step-1.5/tree/main/acestep/training)
- [PEFT Library Documentation](https://huggingface.co/docs/peft)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [ACE-Step 1.5 Gradio Guide](https://github.com/ace-step/ACE-Step-1.5/blob/main/docs/en/GRADIO_GUIDE.md)

---

## ë§ˆë¬´ë¦¬

ACE-Step 1.5 ì™„ë²½ ê°€ì´ë“œ ì‹œë¦¬ì¦ˆë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ì´ì œ ì—¬ëŸ¬ë¶„ì€:

- âœ… ACE-Step ì„¤ì¹˜ ë° ì„¤ì •
- âœ… ëª¨ë¸ ì•„í‚¤í…ì²˜ ì´í•´
- âœ… íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±
- âœ… ê³ ê¸‰ ê¸°ëŠ¥ í™œìš© (Cover, Repaint, Multi-Track)
- âœ… LoRAë¡œ ì»¤ìŠ¤í…€ ëª¨ë¸ í›ˆë ¨

ACE-Stepì„ í™œìš©í•˜ì—¬ ë©‹ì§„ ìŒì•…ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”! ğŸµ
