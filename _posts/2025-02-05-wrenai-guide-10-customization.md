---
layout: post
title: "WrenAI ì™„ë²½ ê°€ì´ë“œ (10) - í™•ì¥ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•"
date: 2025-02-05
permalink: /wrenai-guide-10-customization/
author: Canner
categories: [AI ì—ì´ì „íŠ¸, WrenAI]
tags: [WrenAI, Customization, Extension, Pipeline, Plugin]
original_url: "https://github.com/Canner/WrenAI"
excerpt: "WrenAIì˜ íŒŒì´í”„ë¼ì¸ê³¼ ê¸°ëŠ¥ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ê³  í™•ì¥í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤."
---

## ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°œìš”

WrenAIëŠ” ë‹¤ì–‘í•œ ìˆ˜ì¤€ì˜ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ ì§€ì›í•©ë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ì»¤ìŠ¤í„°ë§ˆì´ì§• ë ˆë²¨                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”§ ì„¤ì • ë ˆë²¨: config.yaml ìˆ˜ì •                             â”‚
â”‚  ğŸ“ í”„ë¡¬í”„íŠ¸ ë ˆë²¨: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •                     â”‚
â”‚  ğŸ”Œ íŒŒì´í”„ë¼ì¸ ë ˆë²¨: íŒŒì´í”„ë¼ì¸ ì¶”ê°€/ìˆ˜ì •                   â”‚
â”‚  ğŸ› ï¸ ì½”ë“œ ë ˆë²¨: ì†ŒìŠ¤ ì½”ë“œ ì§ì ‘ ìˆ˜ì •                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì¡°ì •

```yaml
# config.yaml
settings:
  # í…Œì´ë¸” ê²€ìƒ‰ ì„¤ì •
  table_retrieval_size: 15              # ê¸°ë³¸ 10 â†’ 15
  table_column_retrieval_size: 150      # ê¸°ë³¸ 100 â†’ 150

  # ìœ ì‚¬ë„ ì„ê³„ê°’
  historical_question_retrieval_similarity_threshold: 0.85  # ê¸°ë³¸ 0.9 â†’ 0.85
  sql_pairs_similarity_threshold: 0.65   # ê¸°ë³¸ 0.7 â†’ 0.65

  # SQL ìˆ˜ì • ì¬ì‹œë„
  max_sql_correction_retries: 5          # ê¸°ë³¸ 3 â†’ 5
```

### ê¸°ëŠ¥ í† ê¸€

```yaml
settings:
  # ì˜ë„ ë¶„ë¥˜ ë¹„í™œì„±í™” (í•­ìƒ TEXT_TO_SQL)
  allow_intent_classification: false

  # SQL ì¶”ë¡  ë‹¨ê³„ ë¹„í™œì„±í™” (ë” ë¹ ë¥¸ ì‘ë‹µ)
  allow_sql_generation_reasoning: false

  # SQL í•¨ìˆ˜ ê²€ìƒ‰ í™œì„±í™”
  allow_sql_functions_retrieval: true

  # SQL ì§„ë‹¨ í™œì„±í™”
  allow_sql_diagnosis: true

  # ì»¬ëŸ¼ í”„ë£¨ë‹ í™œì„±í™”
  enable_column_pruning: true
```

---

## í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### SQL ìƒì„± í”„ë¡¬í”„íŠ¸

```python
# src/pipelines/generation/sql_generation.py

SQL_GENERATION_SYSTEM_PROMPT = """
You are a SQL expert assistant.
Generate accurate SQL queries based on the user's question and provided schema.

Rules:
1. Use only the tables and columns provided in the schema
2. Always use proper JOIN conditions
3. Use explicit column aliases for calculated fields
4. Handle NULL values appropriately
5. Use appropriate aggregation functions

Language: Generate SQL comments in {language}
"""

# ì»¤ìŠ¤í„°ë§ˆì´ì§• ì˜ˆì‹œ: íŠ¹ì • DB ë°©ì–¸ ì¶”ê°€
SQL_GENERATION_SYSTEM_PROMPT_SNOWFLAKE = SQL_GENERATION_SYSTEM_PROMPT + """
Additional Snowflake Rules:
- Use ILIKE for case-insensitive matching
- Use :: for type casting (e.g., column::VARCHAR)
- Use FLATTEN for nested JSON
"""
```

### ì°¨íŠ¸ ìƒì„± í”„ë¡¬í”„íŠ¸

```python
# src/pipelines/generation/chart_generation.py

CHART_GENERATION_SYSTEM_PROMPT = """
You are a data visualization expert.
Generate Vega-Lite specifications for the given data.

Guidelines:
1. Choose appropriate chart type based on data characteristics
2. Use clear labels and titles
3. Apply color schemes appropriately
4. Consider accessibility (colorblind-friendly palettes)

Output: JSON Vega-Lite specification only
"""
```

---

## íŒŒì´í”„ë¼ì¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ìƒì„±

```python
# src/pipelines/generation/custom_sql_generation.py

from src.core.pipeline import BasicPipeline
from src.providers.llm import LLMProvider
from src.providers.document_store import DocumentStoreProvider

class CustomSQLGenerationPipeline(BasicPipeline):
    def __init__(
        self,
        llm_provider: LLMProvider,
        document_store: DocumentStoreProvider,
        custom_rules: list[str] = None
    ):
        self.llm = llm_provider
        self.store = document_store
        self.custom_rules = custom_rules or []

    async def run(
        self,
        query: str,
        project_id: str,
        **kwargs
    ) -> dict:
        # 1. ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        context = await self.retrieve_context(query, project_id)

        # 2. ì»¤ìŠ¤í…€ ê·œì¹™ ì¶”ê°€
        rules = self.format_custom_rules()

        # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self.build_prompt(query, context, rules)

        # 4. LLM í˜¸ì¶œ
        response = await self.llm.generate(
            prompt=prompt,
            system_prompt=self.get_system_prompt()
        )

        # 5. í›„ì²˜ë¦¬
        sql = self.extract_sql(response)
        sql = self.apply_custom_transforms(sql)

        return {
            "sql": sql,
            "reasoning": response,
            "context": context
        }

    def format_custom_rules(self) -> str:
        if not self.custom_rules:
            return ""
        rules = "\n".join(f"- {rule}" for rule in self.custom_rules)
        return f"\n### CUSTOM RULES ###\n{rules}\n"

    def apply_custom_transforms(self, sql: str) -> str:
        # ì»¤ìŠ¤í…€ SQL ë³€í™˜ ë¡œì§
        # ì˜ˆ: íŠ¹ì • í…Œì´ë¸”ëª… ë³€í™˜, ìŠ¤í‚¤ë§ˆ í”„ë¦¬í”½ìŠ¤ ì¶”ê°€ ë“±
        return sql
```

### íŒŒì´í”„ë¼ì¸ ë“±ë¡

```python
# src/globals.py

from src.pipelines.generation.custom_sql_generation import CustomSQLGenerationPipeline

class ServiceContainer:
    def __init__(self, config: Config):
        # ... ê¸°ì¡´ ì´ˆê¸°í™” ì½”ë“œ ...

        # ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ë“±ë¡
        self.custom_sql_pipeline = CustomSQLGenerationPipeline(
            llm_provider=self.llm_provider,
            document_store=self.document_store,
            custom_rules=[
                "Always use LIMIT 1000 for safety",
                "Prefer window functions over subqueries",
                "Add execution hints for large tables"
            ]
        )
```

---

## ì»¤ìŠ¤í…€ LLM ì œê³µì

```python
# src/providers/llm/custom_llm.py

from src.core.provider import LLMProvider

class CustomLLMProvider(LLMProvider):
    def __init__(self, api_key: str, endpoint: str):
        self.api_key = api_key
        self.endpoint = endpoint

    async def generate(
        self,
        prompt: str,
        system_prompt: str = "",
        **kwargs
    ) -> str:
        # ì»¤ìŠ¤í…€ LLM API í˜¸ì¶œ
        async with httpx.AsyncClient() as client:
            response = await client.post(
                self.endpoint,
                json={
                    "prompt": prompt,
                    "system": system_prompt,
                    "max_tokens": kwargs.get("max_tokens", 4096),
                    "temperature": kwargs.get("temperature", 0)
                },
                headers={
                    "Authorization": f"Bearer {self.api_key}"
                }
            )
            return response.json()["text"]

    async def embed(self, texts: list[str]) -> list[list[float]]:
        # ì»¤ìŠ¤í…€ ì„ë² ë”© API í˜¸ì¶œ
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.endpoint}/embeddings",
                json={"texts": texts},
                headers={
                    "Authorization": f"Bearer {self.api_key}"
                }
            )
            return response.json()["embeddings"]
```

### ì„¤ì •ì—ì„œ ì‚¬ìš©

```yaml
# config.yaml
type: llm
provider: custom_llm
models:
  - alias: default
    api_key: ${CUSTOM_LLM_API_KEY}
    endpoint: https://my-llm-api.com/v1/generate
```

---

## ì»¤ìŠ¤í…€ ë°ì´í„°ì†ŒìŠ¤

```python
# src/providers/engine/custom_engine.py

from src.core.provider import EngineProvider

class CustomEngineProvider(EngineProvider):
    def __init__(self, connection_string: str):
        self.connection_string = connection_string

    async def validate_sql(self, sql: str) -> dict:
        # SQL ê²€ì¦ ë¡œì§
        try:
            # íŒŒì‹±ë§Œ ìˆ˜í–‰ (ì‹¤í–‰í•˜ì§€ ì•ŠìŒ)
            parsed = sqlparse.parse(sql)
            return {"valid": True, "error": None}
        except Exception as e:
            return {"valid": False, "error": str(e)}

    async def execute_sql(self, sql: str) -> dict:
        # SQL ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜
        async with self.get_connection() as conn:
            result = await conn.execute(sql)
            columns = [col.name for col in result.description]
            rows = await result.fetchall()
            return {
                "columns": columns,
                "data": [dict(zip(columns, row)) for row in rows]
            }

    async def get_schema(self) -> dict:
        # ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
        async with self.get_connection() as conn:
            # ë°ì´í„°ë² ì´ìŠ¤ë³„ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì¿¼ë¦¬
            result = await conn.execute("""
                SELECT table_name, column_name, data_type
                FROM information_schema.columns
                WHERE table_schema = 'public'
            """)
            return self.format_schema(await result.fetchall())
```

---

## UI ì»¤ìŠ¤í„°ë§ˆì´ì§•

### í…Œë§ˆ ìˆ˜ì •

```less
// src/styles/variables.less

@primary-color: #1890ff;    // ë©”ì¸ ìƒ‰ìƒ
@link-color: #1890ff;       // ë§í¬ ìƒ‰ìƒ
@success-color: #52c41a;    // ì„±ê³µ ìƒ‰ìƒ
@warning-color: #faad14;    // ê²½ê³  ìƒ‰ìƒ
@error-color: #f5222d;      // ì˜¤ë¥˜ ìƒ‰ìƒ

@font-size-base: 14px;      // ê¸°ë³¸ í°íŠ¸ í¬ê¸°
@border-radius-base: 4px;   // ê¸°ë³¸ í…Œë‘ë¦¬ ë°˜ê²½
```

### ì»¤ìŠ¤í…€ ì»´í¬ë„ŒíŠ¸

```tsx
// src/components/custom/CustomAskInput.tsx

import { Input, Button } from 'antd';
import { useAsk } from '@/hooks/useAsk';

export function CustomAskInput({ projectId }: { projectId: number }) {
  const [question, setQuestion] = useState('');
  const { ask, loading, result } = useAsk();

  const handleAsk = async () => {
    if (!question.trim()) return;
    await ask(projectId, question);
  };

  return (
    <div className="custom-ask-input">
      <Input.TextArea
        value={question}
        onChange={(e) => setQuestion(e.target.value)}
        placeholder="ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."
        autoSize={{ minRows: 2, maxRows: 6 }}
      />
      <Button
        type="primary"
        onClick={handleAsk}
        loading={loading}
      >
        ì§ˆë¬¸í•˜ê¸°
      </Button>
      {result && (
        <div className="result">
          <pre>{result.sql}</pre>
        </div>
      )}
    </div>
  );
}
```

---

## í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

### í”ŒëŸ¬ê·¸ì¸ ì¸í„°í˜ì´ìŠ¤

```python
# src/plugins/base.py

from abc import ABC, abstractmethod

class WrenAIPlugin(ABC):
    @abstractmethod
    def name(self) -> str:
        pass

    @abstractmethod
    async def on_before_ask(self, query: str, context: dict) -> dict:
        """ì§ˆë¬¸ ì „ì²˜ë¦¬"""
        pass

    @abstractmethod
    async def on_after_ask(self, query: str, result: dict) -> dict:
        """ê²°ê³¼ í›„ì²˜ë¦¬"""
        pass

class LoggingPlugin(WrenAIPlugin):
    def name(self) -> str:
        return "logging"

    async def on_before_ask(self, query: str, context: dict) -> dict:
        logger.info(f"Query: {query}")
        return context

    async def on_after_ask(self, query: str, result: dict) -> dict:
        logger.info(f"Result: {result['status']}")
        return result
```

---

## ëª¨ë‹ˆí„°ë§ í™•ì¥

### ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­

```python
# src/monitoring/metrics.py

from prometheus_client import Counter, Histogram

# ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­
ask_requests_total = Counter(
    'wrenai_ask_requests_total',
    'Total number of ask requests',
    ['project_id', 'status']
)

sql_generation_duration = Histogram(
    'wrenai_sql_generation_duration_seconds',
    'Time spent generating SQL',
    ['model']
)

# ì‚¬ìš©
@sql_generation_duration.labels(model='gpt-4o-mini').time()
async def generate_sql(query: str) -> str:
    # SQL ìƒì„± ë¡œì§
    pass
```

---

## ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. ì ì§„ì  ì»¤ìŠ¤í„°ë§ˆì´ì§•

```
1ë‹¨ê³„: ì„¤ì • íŒŒì¼ë¡œ ì¡°ì •
   â†“
2ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
   â†“
3ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ í™•ì¥
   â†“
4ë‹¨ê³„: ì½”ë“œ ìˆ˜ì • (ìµœí›„ì˜ ìˆ˜ë‹¨)
```

### 2. í…ŒìŠ¤íŠ¸ ì‘ì„±

```python
# tests/test_custom_pipeline.py

import pytest
from src.pipelines.generation.custom_sql_generation import CustomSQLGenerationPipeline

@pytest.fixture
def pipeline():
    return CustomSQLGenerationPipeline(
        llm_provider=MockLLMProvider(),
        document_store=MockDocumentStore(),
        custom_rules=["Always use LIMIT"]
    )

async def test_custom_rules_applied(pipeline):
    result = await pipeline.run(
        query="Show all customers",
        project_id="test"
    )
    assert "LIMIT" in result["sql"]
```

### 3. ë²„ì „ ê´€ë¦¬

```bash
# ì»¤ìŠ¤í„°ë§ˆì´ì§• ë¸Œëœì¹˜ ìƒì„±
git checkout -b custom/my-company

# ì—…ìŠ¤íŠ¸ë¦¼ ë³€ê²½ ë³‘í•©
git fetch upstream
git merge upstream/main
```

---

## ìš”ì•½

WrenAIëŠ” ë‹¤ì–‘í•œ ìˆ˜ì¤€ì˜ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ ì§€ì›í•©ë‹ˆë‹¤:

| ë ˆë²¨ | ë°©ë²• | ë‚œì´ë„ |
|------|------|--------|
| ì„¤ì • | config.yaml ìˆ˜ì • | ì‰¬ì›€ |
| í”„ë¡¬í”„íŠ¸ | ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • | ë³´í†µ |
| íŒŒì´í”„ë¼ì¸ | Python í´ë˜ìŠ¤ í™•ì¥ | ë³´í†µ |
| ì½”ë“œ | ì†ŒìŠ¤ ì§ì ‘ ìˆ˜ì • | ì–´ë ¤ì›€ |

---

*ì´ê²ƒìœ¼ë¡œ WrenAI ì™„ë²½ ê°€ì´ë“œ ì‹œë¦¬ì¦ˆë¥¼ ë§ˆì¹©ë‹ˆë‹¤. ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” GenBIì˜ ì„¸ê³„ë¥¼ íƒí—˜í•´ë³´ì„¸ìš”!*
