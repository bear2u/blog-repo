---
layout: post
title: "Claude Code 2.0 가이드 (9) - 컨텍스트 엔지니어링 이해하기"
date: 2025-12-28
permalink: /claude-code-2-guide-09-context-engineering/
author: Sankalp
categories: [AI]
tags: [Claude Code, AI, 컨텍스트 엔지니어링, 토큰, 컨텍스트 윈도우]
original_url: "https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/"
excerpt: "컨텍스트 엔지니어링이란 무엇인지, 왜 에이전트가 토큰 소비 기계인지, 그리고 컨텍스트 열화를 어떻게 관리하는지 알아봅니다."
---

## 잠깐 쉬어가기

다음 기능들로 넘어가기 전에, **컨텍스트 관리 기본**을 살펴볼 가치가 있습니다. 기술적으로 가벼운 분들에게는 조금 어려울 수 있습니다. 포기하지 마세요. 글을 읽어보세요. 이해하지 못하는 것은 Claude에게 설명해달라고 해도 됩니다.

---

## 컨텍스트 엔지니어링이란

### 에이전트는 토큰 소비 기계

하네스 내의 에이전트는 코드베이스와 다른 입력을 읽고, 내용을 편집하고, 쓰기 등을 위해 **능동적으로 많은 도구 호출**을 할 수 있습니다. 이 과정에서 **진행 중인 대화, 즉 컨텍스트 윈도우에 추가되는 많은 데이터**를 생산할 수 있습니다.

Anthropic은 이 정보에서 **제한된 컨텍스트 윈도우에 들어갈 것을 큐레이팅**하는 기술과 과학을 **컨텍스트 엔지니어링**이라고 합니다.

---

## 도구 호출은 어떻게 토큰을 추가하나요?

흐름은 이렇게 작동합니다:

```
컨텍스트 윈도우:
├─ 사용자: "내 커피숍 랜딩 페이지 만들어줘"
│
├─ 어시스턴트: [tool_call: web_search("modern coffee shop landing page design")]
├─ 도구 결과: [10개 결과, 스니펫, URL]           ← ~1.5K 토큰
│
├─ 어시스턴트: [tool_call: read_file("brand-guidelines.pdf")]
├─ 도구 결과: [추출된 텍스트, 색상, 폰트]        ← ~4K 토큰
│  (여기 있어야 함, 모델은 무상태)
│
├─ 어시스턴트: "브랜드 색상으로 따뜻하고 미니멀한 디자인을 만들겠습니다..."
├─ 어시스턴트: [tool_call: create_file("landing-page.html")]
├─ 도구 결과: [성공, 140줄]                      ← ~50 토큰
│
├─ 어시스턴트: [tool_call: generate_image("cozy coffee shop interior")]
├─ 도구 결과: [이미지 URL 반환]                  ← ~30 토큰
│
├─ 어시스턴트: [tool_call: edit_file("landing-page.html")]
├─ 도구 결과: [diff: 히어로 이미지 + 메뉴 섹션 추가] ← ~300 토큰
│
└─ 어시스턴트: "완료! 히어로, 메뉴, 연락처 섹션이 있는 랜딩 페이지입니다."

총: 하나의 작업에 ~6K+ 토큰. 모든 것이 컨텍스트에 남음.
```

---

## 핵심 포인트

여기서 주목할 핵심은 **도구 호출과 도구 호출 출력 모두** 컨텍스트에 추가되어 LLM이 결과를 알 수 있게 한다는 것입니다. 이는 **LLM이 무상태(stateless)**이기 때문입니다 - 컨텍스트 윈도우 외부에 메모리가 없습니다.

대화에 n개의 메시지가 있다고 합시다. 다음 메시지를 보내면, 요청은 다시 LLM에서 n + 1개의 메시지를 처리합니다 ~ 단일 컨텍스트 윈도우.

선택된 도구 호출이 무엇이었는지에 대한 정보를 추가하지 않으면, LLM은 알지 못하고, 출력을 연결하지 않으면 결과를 알지 못합니다. **도구 호출 결과는 빠르게 컨텍스트를 채울 수 있고**, 이것이 에이전트가 매우 비쌀 수 있는 이유입니다.

---

## 컨텍스트 엔지니어링 정의

[effective-context-engineering-for-ai-agents](https://www.anthropic.com/research/effective-context-engineering-for-ai-agents)에서 직접 인용합니다:

> 컨텍스트는 대규모 언어 모델(LLM)에서 샘플링할 때 포함되는 토큰 집합을 말합니다. 당면한 엔지니어링 문제는 원하는 결과를 일관되게 달성하기 위해 LLM의 고유한 제약에 대해 이러한 토큰의 유용성을 최적화하는 것입니다. LLM을 효과적으로 다루려면 종종 컨텍스트로 생각해야 합니다 - 다시 말해: 주어진 시간에 LLM이 사용할 수 있는 전체적인 상태와 그 상태가 어떤 잠재적 행동을 산출할 수 있는지를 고려하는 것입니다.
>
> 컨텍스트 엔지니어링은 "어떤 컨텍스트 구성이 모델의 원하는 행동을 생성할 가능성이 가장 높은가?"에 대한 답을 찾는 것입니다.

---

## 이 글에서 다룬 모든 것이 컨텍스트 엔지니어링입니다

지금까지 논의한 모든 것이 컨텍스트 엔지니어링에 해당합니다:

| 기능/기술 | 컨텍스트 엔지니어링 역할 |
|----------|----------------------|
| 서브 에이전트 | 컨텍스트 분리 |
| 스크래치패드 | 임시 정보 저장 |
| 압축 (Compaction) | 불필요한 컨텍스트 정리 |
| 시스템 리마인더 | 목표 재확인 |

---

## 컨텍스트 열화 (Context Degradation)

### 제한된 컨텍스트 윈도우

LLM의 컨텍스트 검색 성능은 **새로운 토큰이 도입될 때마다 저하**됩니다. 위의 블로그를 의역하면 - 컨텍스트를 **제한된 "어텐션 예산"**으로 생각하세요. 이는 어텐션 메커니즘 자체의 결과로, 쌍별 관계를 모델링하기가 어려워집니다 - 멀리 떨어진 것에 집중하기 어려워지는 것과 같습니다.

### 컨텍스트 윈도우 비교

| 모델 | 컨텍스트 윈도우 |
|------|----------------|
| GPT-5.2 | 400K 입력 토큰 |
| Opus 4.5 | 200K |
| Gemini 3 Pro | 1M |

이러한 컨텍스트 윈도우의 **효과**도 다를 수 있고, 길이만이 중요한 것이 아닙니다. 그렇긴 해도 900K 길이의 입력에서 무언가를 물어보려면, **Gemini 3 Pro로만 가장 신뢰할 수 있게** 할 수 있을 것입니다.

### Chroma의 컨텍스트 열화 연구

Chroma의 context rot 글은 **작업 난이도가 아닌 길이에 따른 성능 저하**를 보여주는 일부 실험을 깊이 다룹니다.

---

## 실용적인 규칙

대략적인 추론을 도출할 수 있습니다:

> **효과적인 컨텍스트 윈도우는 아마도 50-60% 또는 그 이하입니다.**

대화 중간에 복잡한 작업을 시작하지 마세요. 압축을 하거나 새로운 것을 시작하세요.

---

## 컨텍스트 엔지니어링의 목표

지금까지 본 프롬프트와 코드에서 수행되는 모든 것의 목표:

1. **가장 관련 있는 컨텍스트 연결**
2. **컨텍스트 부풀림 / 관련 없는 컨텍스트 줄이기**
3. **모델이 따르기 쉽도록 적고 충돌하지 않는 지시**
4. **리마인더와 런타임 주입을 통해 도구 호출 개선**

다음 몇 섹션은 더 나은 컨텍스트 관리와 에이전트 성능을 위해 설계된 기능과 구현을 보여줍니다.

---

*다음 글에서는 MCP 서버, 코드 실행, 시스템 리마인더에 대해 알아봅니다.*
