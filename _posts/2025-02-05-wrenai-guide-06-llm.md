---
layout: post
title: "WrenAI ì™„ë²½ ê°€ì´ë“œ (6) - LLM ì—°ë™"
date: 2025-02-05
permalink: /wrenai-guide-06-llm/
author: Canner
categories: [AI ì—ì´ì „íŠ¸, WrenAI]
tags: [WrenAI, LLM, OpenAI, Azure, LiteLLM, Ollama]
original_url: "https://github.com/Canner/WrenAI"
excerpt: "WrenAIì—ì„œ ë‹¤ì–‘í•œ LLM ì œê³µì(OpenAI, Azure, Ollama ë“±)ë¥¼ ì—°ë™í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤."
---

## LLM ì—°ë™ ê°œìš”

WrenAIëŠ” **LiteLLM**ì„ í†µí•´ ë‹¤ì–‘í•œ LLM ì œê³µìë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ì§€ì› LLM ì œê³µì                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â˜ï¸  í´ë¼ìš°ë“œ: OpenAI, Azure, Google, Anthropic, AWS       â”‚
â”‚  ğŸ–¥ï¸  ë¡œì»¬: Ollama, LM Studio, vLLM                         â”‚
â”‚  ğŸ¢  ì—”í„°í”„ë¼ì´ì¦ˆ: Databricks, Snowflake Cortex            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ê¸°ë³¸ ì„¤ì • êµ¬ì¡°

### config.yaml LLM ì„¹ì…˜

```yaml
# LLM ì œê³µì ì„¤ì •
type: llm
provider: litellm_llm
timeout: 120
models:
  - alias: default          # ë³„ì¹­ (í•„ìˆ˜)
    model: gpt-4o-mini      # ëª¨ë¸ëª… (í•„ìˆ˜)
    context_window_size: 128000
    kwargs:
      temperature: 0
      max_tokens: 4096
      seed: 0

# ì„ë² ë”© ëª¨ë¸ ì„¤ì •
type: embedder
provider: litellm_embedder
models:
  - model: text-embedding-3-large
    alias: default
    dimension: 3072
    timeout: 120
```

---

## ì œê³µìë³„ ì„¤ì •

### OpenAI

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: gpt-4o-mini      # ë˜ëŠ” gpt-4o, gpt-4-turbo
    context_window_size: 128000
    kwargs:
      temperature: 0
      max_tokens: 4096

type: embedder
provider: litellm_embedder
models:
  - model: text-embedding-3-large
    alias: default
    dimension: 3072
```

```bash
# .env.local
OPENAI_API_KEY=sk-your-key-here
```

---

### Azure OpenAI

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: azure/your-deployment-name
    context_window_size: 128000
    kwargs:
      api_base: https://your-resource.openai.azure.com
      api_version: "2024-02-15-preview"
      temperature: 0

type: embedder
provider: litellm_embedder
models:
  - model: azure/your-embedding-deployment
    alias: default
    dimension: 1536
    kwargs:
      api_base: https://your-resource.openai.azure.com
      api_version: "2024-02-15-preview"
```

```bash
# .env.local
AZURE_API_KEY=your-azure-key
```

---

### Google AI Studio (Gemini)

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: gemini/gemini-1.5-flash    # ë˜ëŠ” gemini-1.5-pro
    context_window_size: 1000000
    kwargs:
      temperature: 0

type: embedder
provider: litellm_embedder
models:
  - model: gemini/text-embedding-004
    alias: default
    dimension: 768
```

```bash
# .env.local
GOOGLE_API_KEY=your-google-key
```

---

### Google Vertex AI

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: vertex_ai/gemini-1.5-flash
    context_window_size: 1000000
    kwargs:
      vertex_project: your-project-id
      vertex_location: us-central1
```

```bash
# .env.local
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
```

---

### Anthropic Claude

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: claude-3-5-sonnet-20241022
    context_window_size: 200000
    kwargs:
      temperature: 0
      max_tokens: 4096
```

```bash
# .env.local
ANTHROPIC_API_KEY=sk-ant-...
```

---

### AWS Bedrock

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: bedrock/anthropic.claude-3-sonnet-20240229-v1:0
    context_window_size: 200000
    kwargs:
      aws_region_name: us-east-1
```

```bash
# .env.local
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
AWS_REGION_NAME=us-east-1
```

---

### DeepSeek

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: deepseek/deepseek-chat
    context_window_size: 64000
    kwargs:
      temperature: 0
```

```bash
# .env.local
DEEPSEEK_API_KEY=your-deepseek-key
```

---

### Ollama (ë¡œì»¬)

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: ollama/llama3.1:8b
    context_window_size: 128000
    kwargs:
      api_base: http://host.docker.internal:11434
      temperature: 0

type: embedder
provider: litellm_embedder
models:
  - model: ollama/nomic-embed-text
    alias: default
    dimension: 768
    kwargs:
      api_base: http://host.docker.internal:11434
```

```bash
# Ollama ì‹¤í–‰ (Docker ì™¸ë¶€)
ollama serve
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

---

## ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì •

```yaml
type: llm
provider: litellm_llm
models:
  # ê¸°ë³¸ ëª¨ë¸ (ë¹ ë¥¸ ì‘ë‹µ)
  - alias: default
    model: gpt-4o-mini
    context_window_size: 128000
    kwargs:
      temperature: 0

  # ê³ ì„±ëŠ¥ ëª¨ë¸ (ë³µì¡í•œ ì¿¼ë¦¬)
  - alias: advanced
    model: gpt-4o
    context_window_size: 128000
    kwargs:
      temperature: 0

  # ë¹„ìš© ì ˆì•½ ëª¨ë¸
  - alias: budget
    model: gpt-3.5-turbo
    context_window_size: 16000
    kwargs:
      temperature: 0
```

### íŒŒì´í”„ë¼ì¸ì—ì„œ ëª¨ë¸ ì„ íƒ

```yaml
type: pipeline
pipes:
  - name: sql_generation
    llm: litellm_llm.default     # ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©

  - name: chart_generation
    llm: litellm_llm.advanced    # ê³ ì„±ëŠ¥ ëª¨ë¸ ì‚¬ìš©
```

---

## í”„ë¡ì‹œ ë° ì»¤ìŠ¤í…€ ì—”ë“œí¬ì¸íŠ¸

### OpenAI í˜¸í™˜ API

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: openai/custom-model
    kwargs:
      api_base: https://your-custom-endpoint.com/v1
      api_key: your-custom-key
```

### LiteLLM í”„ë¡ì‹œ

```yaml
type: llm
provider: litellm_llm
models:
  - alias: default
    model: your-model-name
    kwargs:
      api_base: http://litellm-proxy:4000
```

---

## ë¹„ìš© ì¶”ì  (LangFuse)

```yaml
settings:
  langfuse_enable: true
  langfuse_host: https://cloud.langfuse.com
```

```bash
# .env.local
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_PUBLIC_KEY=pk-lf-...
```

### ì¶”ì ë˜ëŠ” ì •ë³´

- ëª¨ë¸ëª…
- ì…ë ¥/ì¶œë ¥ í† í° ìˆ˜
- ì˜ˆìƒ ë¹„ìš©
- ì‘ë‹µ ì‹œê°„
- ì„±ê³µ/ì‹¤íŒ¨ ìƒíƒœ

---

## ê¶Œì¥ ëª¨ë¸

| ìš©ë„ | ê¶Œì¥ ëª¨ë¸ | ì´ìœ  |
|------|----------|------|
| **ê¸°ë³¸** | gpt-4o-mini | ë¹ ë¦„, ì €ë ´, ì¶©ë¶„í•œ ì„±ëŠ¥ |
| **ë³µì¡í•œ SQL** | gpt-4o | ë” ì •í™•í•œ ì¶”ë¡  |
| **ë¹„ìš© ì ˆì•½** | gpt-3.5-turbo | ê°€ì¥ ì €ë ´ |
| **í”„ë¼ì´ë²„ì‹œ** | Ollama/llama3.1 | ë¡œì»¬ ì‹¤í–‰ |
| **í•œêµ­ì–´** | gpt-4o | ë‹¤êµ­ì–´ ì§€ì› ìš°ìˆ˜ |

---

## ë¬¸ì œ í•´ê²°

### API í‚¤ ì˜¤ë¥˜

```bash
# í‚¤ í™•ì¸
echo $OPENAI_API_KEY

# í…ŒìŠ¤íŠ¸
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜

```yaml
type: llm
provider: litellm_llm
timeout: 180  # ê¸°ë³¸ 120ì´ˆì—ì„œ ì¦ê°€
```

### Rate Limit ì˜¤ë¥˜

```yaml
kwargs:
  max_retries: 3
  retry_on_timeout: true
```

---

*ë‹¤ìŒ ê¸€ì—ì„œëŠ” í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡°ë¥¼ ì‚´í´ë´…ë‹ˆë‹¤.*
